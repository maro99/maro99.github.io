---
layout: "post"
title: "도서관영화프로젝트19"    
categories:  
- 도서관영화프로젝트      
tags:  
- 일지      
- celery   
- redis 
comments : true    
date: "2018-12-12 18:50"  
---              

# Celery& Redis를 사용한 TaskQueue 시스템 구현 Redis 서버로 ElasticCache 사용     


---   


## 목차     

0. [Django에서 Redis를 이용해 Caching하기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/03/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B813.html) `12.03 완료`  

1. [celery-reids로 local 환경에서 email_sand task](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/04/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B814.html)   `12.04 완료` 

2. [celery+redis로 local환경에서 celery-beat 이용 특정 task 를 que에 넣고 
  정해진 task 알맞은 시간에 수행](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/05/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B815.html)    `12.05 완료` 

3. [celery+redis로 local 환경에서 celery-beat -> 특정task que에 넣고 정해진task >알맞은
  시간에 수행, celery-worker 그때그때 유저 요청시 email-send해주기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/05/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B815.html)   `12.05 완료` 

4. 이거보고 [공식문서](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#generic-initd-celerybeat-example) celery-beat 를 init-script  데몬으로
돌리던거
   예전에  celery-worker init.d에 넣어서 실행시키던거
   [이거](https://www.evernote.com/client/web#?anb=true&b=1917b08f-9255-4138-9cc4-fa196bcd2155&fs=true&n=fb0b1c85-09eb-437b-8f15-15ef1521d68d&s=s372&)   redis>서버 background도는 예제 stackoverflow  찾아서 2번 3번 해보자.
   (가능하면 모두 init.d에 일괄적으로 넣어서 해보고 싶다.)  [링크1](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/06/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B816.html),[링크2](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/07/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B817.html), `중단` 

5. [docker에 넣고 해보기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/09/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B818.html)    
   ( 4번 잘 안되면 여기 넘어와서 dev모드에서 docker안에서  이 셋을 supervisor로
실행시키기)  `12.09완료` 

6. celery-redis로 production에서 elasticcahe사용, 1번 -> 3 번 구현하기 
   `이페이지 이항목 주로 다뤘다.`

7. 내프로젝트에 완전 적용
   소셜로긴, 일반로긴 시 전화번호 받도록 해놓고
   일반로긴시는 (sms인증 or email인증 중 선택할수 있도록.)
   특정 시간에 sms 알람 해보고 --->
   사용자에게 해당 날짜 다가오면 그날 task-que에 알림 쌓아놓고 차례로 보내기.      

---             

## celery-redis로 production에서 elasticcahe사용, 1번 -> 3 번 구현하기    


일단 지금까지 변경사항 base빌드다시 해주고 허브 올려주고 배포다시해봄.    
아 맞다...   
`production/supervisor.conf`  
`settings.production`에 변경사항 업데이트 하고 해라!   
  
이때 url등의 설정은 어떻게 해야 될지?   
포트번호...등 너무 햇갈리네...   
  
우선 rabitmq같은경우는 이렇게 가능한거 같다.      
`broker='amqp://guest:guest@localhost:5672//'`  
   
이건 공식문서  의 예제 보면   
`app.conf.broker_url = 'redis://localhost:6379/0'   `
`redis://:password@hostname:port/db_number ` 

[이글](https://stackoverflow.com/questions/51639652/how-to-configure-docker-to-use-redis-with-celery)도 찾아봤는데   
이글은 `docker-composer`라는걸 쓴다.     
근데 포트 열리는걸 보니... docker file에서는 8000으로 열고~  
`docker-compose.yml` 에서는 8000:8000이렇게 되어있다.    
`app = Celery('server', broker='redis://redis:6379/0') `    
이런식으로 하고있는데... 왜 이런건지 이해도 안됨.   


docker-compose찾아봄   
( 도커컴포스는 컨테이너 여럿 띄우는 도커 어플리케이션 정의 ,실행 하는 도구.dockerfile+   도커런,포트번호등 명령어 합친개념인듯-->결과물인 실행중인 컨테이너는 같다. )
[이글](http://raccoonyy.github.io/docker-usages-for-dev-environment-setup/ )보면~dockerrun할때 8000:8000포트 연결하는거 봐서 우리 9994:80한거랑 비슷한듯.  
  
우리 dockerfile보면 EXPOSE 7000 되어있다.   
우리 nginx설정에 listen7000 되있어서 도커의 7000 으로 오는거 uwsgi와 연결시킴.        
(EXPOSE (필수) Docker 컨테이너에 표시할 포트를 나열합니다. Elastic Beanstalk에서는 포트   값을 사용하여 호스트에서 실행 중인 역방향 프록시에 Docker 컨테이너를 연결합니다. (도커를   실제로 ec2에서 쓸때 세팅을 해놓는것.) 컨테이너 포트를 여러 개 지정할 수 있지만 Elastic   Beanstalk에서는 첫 번째 포트만 사용해 호스트의 역방향 프록시에 컨테이너를 연결하고 퍼블릭   인터넷의 요청을 라우팅합니다. (뭔소리인지 아래서설명))  

```
Browser -> ElasticBeanstalk
    Load Balancer
          ->EC2 -> Nginx(EB)
          (Reverse proxy) 80 -> 7000(Dockerfile EXPOSE)
         ->Docker(Container) :7000 -> Nginx (Docker Container):80-> uWSGI ->Django
```

잠깐 설명 적어보고가자    
```
브라우저에서 요청하면 AWS로 그중에서도 ElasticBeanstalk로 간다.
실제 요청은 Load Balancer가 받는다.
Load Balancer가 받은 요청이 EC2로 오고
EC2에서 Nginx->Docker - > Nginx->uWSGI ->Django로 간다.
앞뒤의 Nginx는 다르다. 앞의 Nginx는 EB안에 지정되어있고 뒤의 Nginx는 Dcoker Contianer에 지정되어있다.
이렇게 EC2 -> Nginx(EB) 까지오고 Docker로 연결되는데
이 과정에서 이것을 연결시키는 것을 역방향 프록시 (Reverse proxy)라는 기법.
nGinx로 어떤 요청중 특정한 값을 프록시가(거처간다는 뜻) 도커 이미지 안으로 넘겨줌.
nginx가 도커(컨테이너-실행중인이미지)로 넘겨줄때
포트값을 사용해서 역방향 프록시에 연결한다.?
만약 도커 컨테이너를 7999로 열어놨다면
nginx가 리버스 프록시로 nginx로 온 요청 nginx 80번을 7999로 보내버린다.
Nginx(EB)와 Docker(Container) 같은 경우에는 EC2안에서 돌아가는 한개한개의 프로세스이다.
이 Nginx가 외부에서온 80번포트에대한 요청 받으면 내부의 도커로 넘기는데 내부 도커가 어느 포트에서 열릴지 모른다.
우리가 열어놓은 포트가 있으면 무조건 거기로 연결된다.
그것이 EXPOSE가 하는 일.
```




이렇게 해줘봄    
```   
CELERY_BROKER_URL = 'redis://redis:6379/0' 
CELERY_RESULT_BACKEND = 'redis://redis:6379/0'   
```   
`eb-ssh`해서 들어가 보니. 셀러리가 reids못찾겠다 한다.....


`docker-compose`에서는 `redis`가하나의 컨테이너로 돌고있으니까 저래 redis를 표시해준거 같다.     
우리는 지금 하나의 컨테이너에서 바보같지만 돌려보려 하고있으니까   
redis빼고이렇게 한번 해줘보겠다.    
```
CELERY_BROKER_URL = 'redis://6379/0' 
CELERY_RESULT_BACKEND = 'redis://6379/0'  
```
다시 해보니 celery에러로그 다음과 같음      
```
[2018-12-11 14:59:53,426: ERROR/MainProcess] consumer: Cannot connect to redis://6379:6379/0: Error 22 connecting to 6379:6379. Invalid argument..
Trying again in 14.00 seconds.  
```   
이걸로 미뤄보아 redis://이것만써도 6370는 자동으로 붙나봄.     
그럼 redis://0만 써주고 해보겠다.   
  

이거 해보니 됬다~   
celery쪽 ~로그   
```
[2018-12-11 15:02:41,815: INFO/MainProcess] Connected to redis://0:6379//
[2018-12-11 15:02:41,824: INFO/MainProcess] mingle: searching for neighbors
[2018-12-11 15:02:42,842: INFO/MainProcess] mingle: all alone
[2018-12-11 15:02:42,868: INFO/MainProcess] celery@3cba02602db1 ready.
```   
redis쪽 ~ 모니터~
```
1544540728.530675 [0 127.0.0.1:41692] "BRPOP" "celery" "celery\x06\x163" "celery\x06\x166" "celery\x06\x169" "1"
1544540729.003704 [0 127.0.0.1:41706] "PUBLISH" "/0.celeryev/worker.heartbeat" "{\"body\": \"eyJob3N0bmFtZSI6ICJjZWxlcnlAM2NiYTAyNjAyZGIxIiwgInV0Y29mZnNldCI6IDAsICJwaWQiOiA5LCAiY2xvY2siOiAxNjYsICJmcmVxIjogMi4wLCAiYWN0aXZlIjogMCwgInByb2Nlc3NlZCI6IDAsICJsb2FkYXZnIjogWzAuMDgsIDAuMjUsIDAuMTddLCAic3dfaWRlbnQiOiAicHktY2VsZXJ5IiwgInN3X3ZlciI6ICI0LjIuMSIsICJzd19zeXMiOiAiTGludXgiLCAidGltZXN0YW1wIjogMTU0NDU0MDcyOS4wMDMyODk1LCAidHlwZSI6ICJ3b3JrZXItaGVhcnRiZWF0In0=\", \"content-encoding\": \"utf-8\", \"content-type\": \"application/json\", \"headers\": {\"hostname\": \"celery@3cba02602db1\"}, \"properties\": {\"delivery_mode\": 1, \"delivery_info\": {\"exchange\": \"celeryev\", \"routing_key\": \"worker.heartbeat\"}, \"priority\": 0, \"body_encoding\": \"base64\", \"delivery_tag\": \"649838dd-02ba-45ba-8db8-4038e8b572fa\"}}"
(근데 redis-cli - h 127.0.0.1처럼 키값 보러 들어가는법은 모르겠다. )
```   
    
beat도 한번 배포적용해보자.-->바로 잘된다.  


`emailsend`도 한번 테스트 해보자.   
--->
이메일보낼시 에러뜨는데...   이거 클릭 해 보니까 됬다.       
```
내 Google 계정에 대한 액세스 허용 보안상의 이유로 새 기기 또는 애플리케이션에 로그인할 때
 Google이 사용자에게 추가 단계를 거치도록 요청할 수 있습니다. 액세스를 허용하려면 아래 '계속' 버튼을 클릭하세요  
 ```
(rabbitmq, redis -> daemon으로 돌고있는것 같다.)     
------>이거 처리해라 로컬에서 돌고있다...왜인지?    

**@일단 이건 패스하자.**   
나처럼 하는 글이 눈씻고 찾아봐도 없는거 같다...   
docker-compose.yml 멀티 컨테이너인거 같은데 공부할겸 한번해볼까? 
django + redis+celery+ceelrybeat 각각 다른 컨테이너에서 돌도록 할 수 있을까?   
추후에 [이글](http://raccoonyy.github.io/docker-usages-for-dev-environment-setup/ ) 참조하면 좋을듯.   






### 본격적으로 elasticcache써서 해보자.
(보고 따라하면 금방 하니까...최대한 보는거 자제하고 공식문서 찾아가면서 해보도록.)   

**왜 elasticache-redis인가?**    
```
- 서버 구축 편의성 및 손쉬운 사용
- Replication을 만들어서 끈기지 않고, 지속가능한 사용성 보장
- 예약인스턴스, 예약노드(이후 RI)로 1년 계약시 비용을 비교하면 가격 면에서 오히려 더 저렴  

캐시의 장점으로서
- 데이터베이스를 참조하는 횟수를 줄일 수 있으며,
- 하드웨어 기반이 아니라 더 빠르게 데이터를 참조할 수 있다.
```      




[블로그 글](https://kahee.github.io/project/2018/07/03/Project_chatbot(5)/) 참고중   elasticcache에서 추과과금 피하는부분 참고해라.  

```
* 기본 설정 되어있는 노드 유형 cache.r4.large를 cache.r4.large으로 변경해야만 초과 요금이 없다. 나의 경우 이부분을 잘 보지 않아 요금을 내야 하는 상황이다ㅜㅜ
* 작은 프로젝트의 경우 복사본을 없음으로 지정해도 괜찮다. 복사본이 있을 경우 상당수 프리티어가 제공하는 시간을 초과하여 추가 요금이 청구되는 경우가 많다.  
```  
[공식문서](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/red-ug/GettingStarted.html ), [기본용어](http://behonestar.tistory.com/49)는 여기 참고중 (근데 이거는  엘라스틱서치 용어라.. 클러스터 등 몰라도될듯.-->클러스터 모드 쓰면 알아야하는데 나는 안쓰겠다. )   
```
클러스터 (Cluster)
* 클러스터는 하나 또는 여러 노드들의 집합
* 클러스터 이름을 기준으로 노드들이 묶임 (기본값 : elasticsearch)
* 데이터를 노드들이 나눠 갖으며 노드들끼리 연합하여 인덱싱과 검색 작업 수행
(이건 뭔가 

노드 (Node)
* 단일 서버이며 클러스터의 구성원
* 데이터를 저장하고 클러스터의 인덱싱과 검색 작업에 참여함

샤드 (Shards)
* 하나의 인덱스는 단일 노드의 용량을 초과할만큼 대량의 데이터 저장 가능
* 인덱스를 관리하면 단일 노드로 용량 및 검색 속도의 한계 존재
* 인덱스를 여러 조각(샤드)으로 나눠서 한계를 극복
* 샤딩을 통해 볼륨을 분할/확장 가능
* 샤딩을 통해 샤드끼리 분산/병렬 처리 가능 → 성능 향상
* 샤드의 개수는 인덱스를 생성할 때 지정 가능
* 인덱스를 생성할 때 샤드 개수 지정. 이후로는 변경 불가. (기본값 : 5)

리플리카 (Replica)
* 리플리카 샤드, 줄여서 리플리카라고 부르기도 함
* 샤드 또는 노드가 장애를 일으키는 경우를 대비하여 하나 이상의 복사본(리플리카 샤드)을 생성
* 높은 가용성 제공을 위해 리플리카는 원본(프라이머리 샤드)과 다른 노드에 존재
```

[이글](http://bucketplace.tistory.com/2) 참조해서 클러스터 생성해보자.    

```
ElastiCache를 구성하기 전에 꼭 알아야하는게 있습니다. 같은 VPC상에 존재해야 하며, 외부는 물론,
다른 VPC에서도 접근이 불가능합니다.

a) Cluster engine 선택
      Redis와 Memcached중에서 자신에게 맞는 엔진을 선택합니다.
      Redis의 경우 Cluster를 이용할 경우에는 Cluster Mode enabled를 선택합니다.
      (저는 Redis로 생성하였으며, 추후 설명은 Redis에 맞춰지게 됩니다.)

   b) Redis settings
     기본적인 Redis설정을 합니다.
     - Name, Description : 이름 및 간단한 설명을 적어줍니다.
     - Engin version compatibility : 사용할 Redis 버전을 선택합니다.
     - Port : Redis에 접속 가능한 포트번호를 적어줍니다. 기본값은 6379이며, 변경하는 것은 별로 추천하고 싶지 않습니다.
     - Parameter group : Cluster Mode를 사용할 경우 중요하며, 그렇지 않으면 기본 그룹을 사용하면 됩니다.
     - Node type : 자신의 서비스 상황에 맞는 성능을 선택하시면 됩니다. 추후 변경이 가능합니다. (온디맨드의 경우만 해당)-------->cache.t2.micro
     - Number of replicas : Slave서버를 몇개를 생성할지 선택합니다. (선택한 수만큼 비례 비용 청구)              --------> 0 

   c) Advanced Redis settings
     왠만하면 고급 설정은 건들지 않는게 다른 곳의 일반적인 상황이지만, ElastiCache는 고급정보도 설정해야합니다.
     - Multi-AZ with Auto-Failover : 서버 오류로 Primary를 사용할 수 없는경우, Slave를 Primary로 변경합니다.
     - Subnet group : cache용 subnet 그룹을 하나 선택 또는 생성하시면 됩니다. 새로 생성할 경우 반드시 VPC가 접속할 인스턴스와 같은 VPC인지 확인합니다.
          > Create new를 선택한 경우 VPC선택 및 이름과 설명을 작성합니다.
     - Preferred availability zone(s) : ElastiCache가 사용 가능한 존을 선택합니다. VPC만 정확히 선택하면 신경쓰지 않으셔도 됩니다.
     - Security groups : b)에서 설정한 Port 번호로 접근 가능한 SG중에서 하나를 선택해줍니다.

        ( subnet이란?  ip 쪼개서 쓰는것. 참고 )
        ( vpc란? VPC는 AWS 서비스 중 네트워크 영역에 속하는 서비스/
        마존 클라우드 내에서 private ip를 사용하는 일종의 가상 private network 망을 만들어줄 수 있게 해주는 서비스  참고 

   d) Import data to cluster, Backup, Maintenance
     중요하지 않은 부분이라 Skip합니다.

C. create 버튼을 클릭하면 수분후에 ElastiCache가 생성됩니다.

D. 가동 테스트 - ElastiCache와 같은 VPC에 있는 EC2에 접속하여, telnet을 이용하여 해당 ElastiCache로 접근합니다.
- 명령어 : telnet [Access-point] [Port]
- 접속에 성공하면 Redis 명령어를 사용해가면서 잘 동작하는지 확인합니다. (Redis 명령어 링크)
```     


좀더좋은 설명들 이곳들 참고  
[참고:darkblank’s blog](https://darkblank.github.io/development/Elasticache/)   
```
borker인자에 생성한 Elasticache 엔드포인트를 넣어주면 Elasticache를 브로커로 사용하게 된다
Elasticache는 로컬에서는 테스트 할 수 없다. 따라서 AWS에서 만든 EC2나 Elastic Beanstalk 에 접속하여 테스트를 해 주어야 한다.
 또한, 자신의 EC2나 Elastic Beanstalk에서 사용하기 위해서 Elasticache 보안그룹 설정에서 인바운드로 해당 EC2나 Elastic Beanstalk의 보안그룹을 추가 해 주어야 한다.
```
아....뭐가 몬지 하나도 모르겠다. 

#### 사실들을 정리해보면 
이미 나는`vpc`라는 것을 사용하고 있었던것 같다. 보안그룹의 항목이 vpc_id인데    
이것 vpc가서 보면 있는거랑 같다. 이거 하나밖에 없으므로     
 기존의 vpc에 이번에 만든 elasticahce의 vpc 가 같다는 것. vpc-b807e0d3 이걸로 같다.   
[이글](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/red-ug/elasticache-vpc-accessing.html ) 보면 그냥`인바운드 규칙 추가`하면 되는것 같기도한데...  
4개의 보안그룹 (loadbalacner, ec2, rds중 어디에 추가해야 하나싶다. 당연히 ec2인가 ?    

이런 내용도 눈에 띈다.  
```
Security groups : b)에서 설정한 Port 번호로 접근 가능한 SG중에서 하나를 선택해줍니다.
Memcached와 마찬가지로 클러스터 생성이 완료되기까지는 몇 분 정도가 소요된다. 클러스터 생성이 완료되기 전까지 해당 노드에 접속하기 위해 Security Group을 변경한다. Security Group을 설정하는 방법에 대해서는 이곳을 참고한다. Inbound로 위의 Port에서 지정한 6379 TCP 포트를 추가한다.
...
클러스터 생성이 완료되고 Security Group을 만들고 나면 클러스터를 선택 후 상단의 Modify 버튼을 클릭한다.
VPC Security Group에 방금 새로 만든 Security Group을 같이 지정한다. Security Group은 복수 선택하여 함께 지정할 수 있다. 설정이 완료되면 Modify 버튼을 클릭한다.
```   


아니다  공식문서 보니   
![이미지](https://imgur.com/zZBQtKz.png)   

이런식으로 기존에 있는 ec2를 포트 6379로 연결하는것 같다.    


이것을 elasiti_cache_movie 수정해서 추가한다.   
(기존의 default_vpc보안그룹 과 같이 쓰는듯.)       

[이글](http://pyrasis.com/book/TheArtOfAmazonWebServices/Chapter15/07 ) 다시 참조해보자..잘나온듯!    
(여기는 근데 엡을 추가하는게 아니고~그냥 모든 source에 대해서 연결을 허용하는것 같다.   어짜피 같은 vpc안에서만 접속 가능하니까 그런듯)  
```
ElastiCache Redis 클러스터와 캐시 노드가 완전히 생성되었더라도 엔드포인트 주소로 접속이 되지 않습니다. Redis 클러스터를 생성할 때 Security Group을 기본값인 default (VPC)로 설정했습니다. 이 default (VPC)는 모든 트래픽에 대해 Inbound가 열려있지만접속 가능한 IP 대역Source은 default 자기 자신으로 설정되어 있습니다. 즉 같은 default (VPC) Security Group 설정 안에서만 접속이 허용되므로 외부에서는 접속할 수 없습니다. 따라서 Redis 클러스터 전용 Security Group을 생성하고 포트(6379)를 열어줘야 합니다.
RDS와 ElastiCache는 큰 차이점이 있습니다. RDS의 데이터베이스 엔진은 AWS 외부(인터넷)에서 접속이 허용되어 있지만 ElastiCache의 캐시 엔진은 AWS 외부에서 접속할 수 없습니다. Security Group을 생성하여 모든 IP 대역에 대해 접속을 허용하더라도 동일한 VPC에 속한 EC2 인스턴스에서만 접속할 수 있습니다.

자세한 내용은 링크를 참조하기 바랍니다.
http://aws.amazon.com/ko/elasticache/faqs/#general-security

ElastiCache Redis 클러스터용 Security Group을 생성해보겠습니다. AWS 콘솔의 메인 화면에서 Compute & Networking의 EC2를 클릭합니다.

외부에서 들어오는 트래픽인 Inbound 탭을 선택합니다(Inbound가 기본으로 선택되어 있을 것입니다). 아래쪽 Add Rule 버튼을 클릭합니다.
* Type: 트래픽 종류입니다. Memcached는 미리 정의된 것이 없으므로 Custom TCP Rule을 선택합니다.
* Protocol: 프토로콜입니다. Custom TCP Rule 선택하면 자동으로 TCP가 설정됩니다.
* Port Range: 포트 번호입니다. 우리는 Memcached 포트를 열어야 하므로 11211을 입력합니다.(우리는 6379인듯)  
* Source: 접속 가능한 IP 또는 IP 대역입니다. Anywhere를 선택합니다(실무에서는 My IP를 선택하여 자신의 IP만 접속할 수 있도록 설정하거나, Custom IP를 선택하여 특정 IP 대역을 설정하도록 합니다).
설정이 완료되었으면 Create 버튼을 클릭합니다.

ElastiCache 캐시 클러스터 목록에서 Memcached 클러스터(examplememcached)에 있는 Modify 버튼을 클릭합니다.

ElastiCache Redis 클러스터의 설정을 변경합니다. VPC Security Group(s)에서 방금 생성한 Redis Cluster를 선택하고 아래쪽 Yes, Modify를 클릭합니다.
```

![](https://imgur.com/SzGlHKY.png)


확인  
```
Redis는 텔넷telnet으로 접속할 수 있습니다. 앞에서 생성한 EC2 인스턴스(Example Server)에서 텔넷을 이용하여 Redis 캐시 노드로 접속해보겠습니다(아직 EC2 인스턴스를 생성하지 않았다면 ‘4.3 EC2 인스턴스 생성하기’를 참조하여 EC2 인스턴스를 생성하기 바랍니다).
telnet <엔드포인트 주소> 6379 순으로 명령을 입력하면 Redis 캐시 노드로 접속할 수 있습니다. 접속한 후 info를 입력하면 현재 캐시 노드의 정보가 표시됩니다.

exampleredis.o5nouc.0001.apne1.cache.amazonaws.com는 제가 생성한 캐시 노드 엔드포인트 주소 입니다. 여러분들이 생성한 캐시 노드의 엔드포인트 주소를 입력하기 바랍니다.

접속이 되지 않는다면 Security Group에 포트 번호를 정상적으로 입력하였는지, Memcached 클러스터 설정에서 방금 생성한 Security Group을 선택하였는지, 텔넷 접속에서 엔드포인트 주소와 포트 번호를 정확하게 입력하였는지, EC2 인스턴스가 같은 VPC에 속해 있는지 확인합니다.
앞에서 설명한 것처럼 ElastiCache의 캐시 노드는 AWS 외부에서 접속할 수 없습니다.
```

내경우 
`eb ssh`

`sudo yum install telnet` (참고)
`sudo yum install telnet-server`
`telnet movie-cache-redis.a6uggn.0001.apn2.cache.amazonaws.com 6379`

`info` 

```
telnet exampleredis.o5nouc.0001.apne1.cache.amazonaws.com 6379
Escape character is '^]'.
info
$1747
# Server
redis_version:2.8.6
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:37f1586c49770bbe
redis_mode:standalone
os:Amazon ElastiCache
arch_bits:64
multiplexing_api:epoll
gcc_version:0.0.0
process_id:1
run_id:6e1a8b8dacf399db74b53526ed722c9820e8e20b
tcp_port:6379
생략...
```

이런식으로나온다. 
혹은 `MONITOR` --->OK  



**배포 환경 수정**

```
settings/proudciont.py
CELERY_BROKER_URL = 'redis://' + AWS_ELASTIC_CACHE
CELERY_RESULT_BACKEND = 'redis://' + AWS_ELASTIC_CACHE
``` 
후 에드 하고 배포해보자. 

오 잘되는거 같다.  
근데 이제 `superviosr`에서 `redis`실행해줄 필요없다.   
도커안에서 `redis` 도는것이 아니니까!    
monitor도 eb ssh해서 들어가서 elasticache의 ~엔드포인트에서 해줘야한다.     
키 관찰은 어떻게 하는지? ------> 엔드포인트에서 `KEY`S * 하면 보임   

일딴 supervisor에서 빼주고 해보자. 음 잘했다.   
   
메일 보내는것도 테스트 해보자 -->  잘된다.    



