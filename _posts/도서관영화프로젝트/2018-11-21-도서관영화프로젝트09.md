---
layout: "post"
title: "도서관영화프로젝트09"    
categories:  
- 도서관영화프로젝트      
tags:  
- 일지       
comments : true    
date: "2018-11-21 18:50"  
---   


## celery 써서 회원가입 이메일 인증 비동기화 시작  

---   
### 목차 

1. 기본적인  python 프로젝트에서 test, django project에서 테스트 
2. 내 프로젝트 email 보내는 것에 celery적용시킴. 
3.  CELERY_BROKER_URL 등 따로 settings.base에 선언 해 줘야 하나?? 
4. 어떻게 배포시 백그라운드에서  worker가 돌게 할 것인가? 
      4.1.celery multi start worker1 사용  
      4.2.init service로 등록
      4.3.celery-beat 이건 reids할때 같이 해보자   

5. 어떤 함수를 워커가 대신 해주도록 셀러리가 전달할때   
표시해 놓는방법은?





### 1. 기본적인  python 프로젝트에서 test, django project에서 테스트    
[여기](http://whatisthenext.tistory.com/127)주로 참고중   
[장고~셀러리 연동 공식문서](https://beomi.github.io/2016/11/04/eb-b2-88-ec-97-ad-ec-9e-a5-ea-b3-a0django-ec-99-80-ed-95-a8-ea-bb-98-ed-95-98-eb-8a-94-celery-ec-b2-ab-ea-b1-b8-ec-9d-8c/) 잘 해석 되있는곳  

했던것 대략적으로 정리해보면   

1. 워커서버를켜놓고 대기를 하고 있는 상태 .(woker를 생성)
    `celery -A config  worker -l info` 만들어 놓고 

2. 장고 프로젝트 내부의 어떤 함수의 실행을 워커서버로 넘긴다.  
    `long_task()`경우  `logn_task.delay()`

3. 이렇게 할수 있는 이유는 
    `logn_taks()`위에 `@celery_app.task`
    이 값이 적혀있기 때문에 

좀더 자세히 살펴보자.     

**장고 프로젝트 `app/config` 의  `celery.py` 에 
 `Celery 인스턴스(app)`을 정의 해 놓아야 한다.**   
 
 **app/config/celery.py**
 ```
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')     # 셀러리 app실행시 장고 환경변수 가져오는 것인듯. 
    app = Celery('config')                                                # 셀러리 객체 생성 
    app.config_from_object('django.conf:settings', namespace='CELERY')       #셀러리에서 기본으로 쓸 settings모듈을 장고  에서 가져다 쓰는
    app.autodiscover_tasks()                                        # 프로젝트 안의 모든 app에서 tasks를 찾는다. 
                                                   #이렇게 하면 각각의 모듈에 CELERY_IMPORTS를 추가 안해도 된다. 
    @app.task(bind=True) 
    def debug_task(self):                             # 엡 자신의(?) request 정보를 dumps 하는 task
            print('Request: {0!r}'.format(self.request))
 ```   
 
**위 `Celery 인스턴스(app)`을 `app/config/__init__`에서 import 해준다.  
이렇게 하면 장고가 시작할때 `Celery인스턴(app)`이 load된다  
.--->`@shared_task`라는 데코레이터가 이걸 사용한다.**   


**app/config/__init__.py**
 ```
__all__ = ('celery_app',)
```

`shared_task`라는 데코레이터 는 구체적신 `celelry app`을 가직고 있지  
않아도 너 의(각 함수의)  task (장고엡 -->ravbitmq로 보내고 celery에 시키는)  
을 생성하게 해준다.  ( 재사용 가능한 엡의 경우 하나의 프로젝트 자체에 종속되면  
안되는데 그런 엡을 작성할 경우 각각에서 위에 작성한  
celery app을 iport하는 과정 있으면  다른 프로젝트에선 __init__에 celelry_app   
정의 안되있어서 애러뜬다. 그래서 이런식으로 가져다 쓰도록   
데코레이터 놓고 자체 검색 하도록 한듯.)    
```
    @shared_task
    def add(x,y):
        return x+y
```   

그밖에 [글1](http://abipictures.tistory.com/895), [글2](http://ngee.tistory.com/540?category=560971) 많이 참고했다.   

### 2. 내 프로젝트 email 보내는 것에 celery적용시킴.   
빠르게 적용했다. [내깃](https://github.com/maro99/library_movie/commit/191a59d437afaa5897c6ebd77a03ed95ea647538)에 코드 업로드했다.    

### 3. CELERY_BROKER_URL 등 따로 settings.base에 선언 해 줘야 하나??   
내 생각에는 주로 참고한 글에서 는 따로 써주는것 같은데 그건 3년전 버전이라서 써준듯.
요즘 4.x 버전에서 `os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')`       
로 다 되는것인가? -->근데 여기도 저런건 선언 해 놓은적없지않나 ? 

결국    
`os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings.local')` 해줌   

### 4. 어떻게 배포시 백그라운드에서  worker가 돌게 할 것인가?    


[질문](https://stackoverflow.com/questions/12814691/run-a-celery-worker-in-the-background) 찾아봤다.     
```
In production you’ll want to run the worker in the background as a daemon. To do this you need to use the tools provided by your platform, or something like supervisord (see Daemonization for more information).
For a complete listing of the command-line options available, do:  

$ celery worker --help

There are also several other commands available, and help is also available:

$ celery help

```  

[Daemonization](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#daemonizing) 이 링크가 공식 문서. 이것도 계속 참고하다가 ....  
Daemonization 이 링크가 공식 문서. 이것도 계속 참고중.   


이해하기 어려워서 [여기](http://ngee.tistory.com/563) 들어가 봄.



보던거 일단 접고   

여기 들어가보니 튜토리얼 설명 해놯는데 3가지 방법이 있는것 같다. 

1. **celery multi start worker1** 사용  

2.  **init service**로 등록 (root user를 써야하는데.. 위 링크에선 안나오는듯 ..)

3. **celerybeat** 사용   
    (주기적으로 어떤 통계를 도출해 낸단더지 하는 배치  
    (일괄 처리)작업이 필요한 경우가 종종 생기는데 이때 Celery를 이용할 수 있다. 작업큐에 주기적으로 필요한 작업들을 넣어주면 되는데 이 역할을 하는것이   
    Celery에 포함된 beat라는 녀석이다. 홈페이지의 설명에 따른 celery beat는  
    스케쥴러이다)  
    -->이건 다음주에 크롤링 1시간에 한번씩 하도록 dev- rds +  reddis(로컬)해보고
    production-rds + reddis(elastic cache)로 배포상태에서 해보자.    




