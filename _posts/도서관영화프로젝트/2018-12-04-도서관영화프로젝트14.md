---
layout: "post"
title: "도서관영화프로젝트14"    
categories:  
- 도서관영화프로젝트      
tags:  
- 일지      
- celery   
- init.d   
- redis  
- caching  
comments : true    
date: "2018-12-04 18:50"  
---              

# Celery& Redis를 사용한 TaskQueue 시스템 구현 Redis 서버로 ElasticCache 사용     


---   


## 목차     

0. [Django에서 Redis를 이용해 Caching하기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/03/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B813.html) `12.03 완료`  

1. celery-reids로 local 환경에서 email_sand task `이 페이지에서는 이항목 주로 다뤘다.`

2. celery+redis로 local환경에서 celery-beat 이용 특정 task 를 que에 넣고
  정해진 task 알맞은 시간에 수행

3. celery+redis로 local 환경에서 celery-beat -> 특정task que에 넣고 정해진task >알맞은
  시간에 수행, celery-worker 그때그때 유저 요청시 email-send해주기

4. 이거보고 [공식문서](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#generic-initd-celerybeat-example) celery-beat 를 init-script  데몬으로
돌리던거
   예전에  celery-worker init.d에 넣어서 실행시키던거
   [이거](https://www.evernote.com/client/web#?anb=true&b=1917b08f-9255-4138-9cc4-fa196bcd2155&fs=true&n=fb0b1c85-09eb-437b-8f15-15ef1521d68d&s=s372&)   redis>서버 background도는 예제 stackoverflow  찾아서 2번 3번 해보자.
   (가능하면 모두 init.d에 일괄적으로 넣어서 해보고 싶다.)

5. docker에 넣고 해보기
   ( 4번 잘 안되면 여기 넘어와서 dev모드에서 docker안에서  이 셋을 supervisor로
실행시키기)

6. celery-redis로 production에서 elasticcahe사용, 1번 -> 3 번 구현하기

7. 내프로젝트에 완전 적용
   소셜로긴, 일반로긴 시 전화번호 받도록 해놓고
   일반로긴시는 (sms인증 or email인증 중 선택할수 있도록.)
   특정 시간에 sms 알람 해보고 --->
   사용자에게 해당 날짜 다가오면 그날 task-que에 알림 쌓아놓고 차례로 보내기.  

## 1) celery-reids로 local 환경에서 email_sand task  

**질문**  
`django-redis`이용 --> django porject의 view등에서 보여주는 정보들 caching하는거랑    
셀러리들한테 일시키는거랑 뭔상관인지?   
셀러리들한태 일시키는 방식이 redis를 큐로 활용해서      
키 : 작업 이런식으로 저장해서 키값가지고 작업 조회해서 worker에게 분배해야 될탠데...    

찾아보니 두종류의 튜토리얼들 있다.    

1. 장고에서 redis를 이용해서 caching하는 튜토리얼    
      django-redis  ---> pipenv install
      redis-tools--------> apt-get  install
      redis-server-------> apt-get install


2. 장고에서 redis이용해서 celery에게 줄 업무를 broking하기위한 que만드는데 redis를           사용하는 튜토리얼 
   레디스자체를 인메모리에 먼저 까는듯.  ---> 
   장고프로젝트에 celery, redis추가.  
   pipenv install redis
   pipenv install celry

두가지 사례 공통점은, redis를 뭔가 인메모리  
(apt-get사용 redis-server설치 , or  redis-stalbe~~ )에도 설치하고   
장고프로젝트의 가상환경에도 따로 (pipenv사용 redis or django-redis ) 설치 해준다는것. 


**redis명령어들 앞서서 django-redis-cache에서 썼던것 보고가자**   
`/etc/init.d/redis-server restart` redis 서버 재 시작   
`/etc/init.d/redis-server stop`  redis 서버 정지     
`/etc/init.d/redis-server start`  redis 서버 시작   

`redis-cli -h 127.0.0.1 -p 6379`   해당 redis 서버 주소 가서 조회   
`SELECT 1 `  
`KEY *`      

**햇갈리는것들**     

1) redis,

2) django-redis
    django에서 redis이용해 caching하기 튜토리얼 에서 썼던것.
    full featured Redis cache/session backend for Django. 
    (장고를 위한 래디스~캐시/세션 백엔드)  
   
3) django-redis-cache 


**모르겠다... 일단  튜토리얼 따라해보자.**
[경영학도 Django+celery+Redis이용하기](http://whatisthenext.tistory.com/127) 참고중   

이하는 위에서 퍼왔다.   

**1-1 Celery 설치하기**  
`$ pip install 'celery[redis]'`   

**1-2 Redis 설치하기**
```
$ wget http://download.redis.io/redis-stable.tar.gz ->로컬의project/dowonloads에서 했다. 
$ tar xvzf redis-stable.tar.gz
$ cd redis-stable
$ make
$ redis-server # redis 실행
$ redis-cli ping # 정상 설치되었는지 확인
> PONG   
```

**[프로젝트 폴더] / [환경설정 폴더] / __init__.py**
```
`from .tasks import app as celery_app`
__all__ = ['celery_app']
```

**[프로젝트 폴더] / [환경설정 폴더] / settings.py**  
```
BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'
```

**[프로젝트 폴더] / [환경설정 폴더] / tasks.py(파일 추가)**

```
import os
from celery import Celery
 
# `celery` 프로그램을 작동시키기 위한 기본 장고 세팅 값을 정한다. 
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
 
app = Celery('config')
 
# namespace='CELERY'는 모든 셀러리 관련 구성 키를 의미한다. 반드시 CELERY라는 접두사로 시작해야 한다. 
app.config_from_object('django.conf:settings', namespace='CELERY')
 
# 장고 app config에 등록된 모든 taks 모듈을 불러온다. 
app.autodiscover_tasks()
 
@app.task
def add(x, y):
    return x + y  
```  
    
    
**실행하기**
주의점 : 프로젝트 폴더에 진입한 뒤! 쉘에서 다음 명령을 입력해야 한다.

```
$ celery -A   [파일이름]   worker --loglevel=info
$ cerlry -A    config    worker --loglevel=info   
```

**redis설치**  
```
$ wget http://download.redis.io/redis-stable.tar.gz
$ tar xvzf redis-stable.tar.gz
$ cd redis-stable
$ make
```
**서버 시작**
`$ redis-server`  

**서버 확인**  
`$ redis-cli`
 ```
127.0.0.1:6379 > ping
PONG
```   
**서버 정지**
`$ redis-cli shutdown`  

#### 내가 다시 정리해 보면 위 튜토리얼은   
config의 init.py에  tasks.py에 생성한 app   
즉 app = Celery('config')  셀러리 객체를  이 프로젝트에서   
celery명령문 쓸때 쓰도록 한것이 정의 되어있다.    
또한 어떤 task를 (여기선 함수 add)   
셀러리에게 맞길것인지 해당 함수 위에 @app.task 데코레이터를 붙여놨다.    

실행순서는 정리해보면 다음과 같음  
```
셀러리 워커 실행  
celery -A config  worker --loglevel=info        
(이렇게 하면 주기적으로 config/__init__ 의 all에 포함된 cellery_Settings의 app이 주기적으로 실행됨 

redis서버 실행 
redis-server 
BROKERURL = 'redis://localhost:6379/0' 이어서 이 주소에 redis 서버 실행된다.  
--->앞으로 이서버 저장소(redis)를 
장고로 부터 전달받은 tasks 를 쌓아두는 que를 위해 쓴다. 
또한  CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'  여서 여기에 tasks의 진행상태?아이디 등이 보인다. 
(문서 찾아보니 메시지 브로커는 rabitmq, resultbackend는 redis따로 쓸수도 있다.)


장고 -> redis
@app.task.데코레이터 붙은 함수를 add.delay(4,4) 이런식으로 실행하면  
BROKERURL 에서 실행중인 redis backend에 (저장소에  큐에?_ 해당 task(더하기연산을 하시오)가 저장된다. 

redis - > celery
redis에서는 이것을 차례로 꺼내서 celery의 워커에게 위임한다. 


이걸 redis 서버 가서 확인해본다.   
redis-cli -h 127.0.0.1 -p 6379  
SELECT 0
OK
127.0.0.1:6379> KEYS *
1) "celery-task-meta-0a1e136d-987a-4fc4-a3ec-bd4b5e794bb8"
2) "celery-task-meta-26374170-f910-4289-bf08-6fc6f7561de5"
3) "celery-task-meta-95e8c27d-81ec-49a8-8be7-d7cb7e6deeb2"
4) "celery-task-meta-1139edf4-8e46-4ecb-8477-fc8998384b55"

위의 값들은 celery의 worker켜논곳에서 같이 뜨는 값들이다. 즉 여기를 거쳐서 celery worker에게 일시킨것.  
```   

**내가 기존에 내 프로젝트의 경우**  
local + rabbitmq할때 만들어 놓은것   에선    
`brokerurl`, `celery_result_backend` 모두 그냥 `default` 로 `broker='pyamqp://')`    
이런거 알아서 썼던것 같다.     

또한 그때는 celery 의 app (객체)를 `config/celery_settings`에 선언해놓고   
`members`에 따로 만든 `tasks.py` 에    
`taks`로 맞길 (.delay쓸) `send_email`함수를 따로 지정해 놓았다.    
(위 redis+celery 예제에서는 `tasks.py`에서` app`도 만들고 `task`도 선언해버려서 그냥 여기서    다한다.  
작은 프로젝트에서는 이렇게 하기를 문서에서는 권장한다.)     

질문.  
근데 이렇게 한게 `redis`의 `cache`기능을 쓰고있는것인가?   
`redis`자체가 인메모리 저장소여서 그냥 그자체 캐쉬맞나? --->맞는듯.    

### **이제 기존 email_send에 redis를 사용해 보겠다.(local에서)**  

깃처럼 바꿔주고     
창 1 `celery -A config  worker --loglevel=info`

창 2 `redis-server`

창 3 `runserver`   

postam에서 이메일 회원가입 진행 해봄.  

`redis-cli -h 127.0.0.1 -p 6379`  에접속 해보니 
`celery` 실행 창에 있는 키값?이 같은게 보였다. 잘 주고 받은듯.     

**질문**    
궁금한게 reddis는  celery+redis연동시 따로 서버 켜주는데 rabbitmq에서는 왜 안켜줬던거지?  
```
`$ sudo apt-get install rabbitmq-server`
When the command completes, the broker will already be running in the background, ready to move messages for you: Starting rabbitmq-server: SUCCESS
```
위 튜토리얼에서 가져온글 보면 `rabbitmq`설치완료시 `rabbitmq`브로커가 실행되고 있다함.  
그렇다면 설치된 이후 줄곳 실행중인것인가? ㄷㄷㄷ.....  
  
이문서들어가보니   
  
`rabbitmq` 시작, 종료 명령어 따로 있었다.   
`$ sudo rabbitmqctl stop`  
일단 위에거 사용해서 종료해 놓았다..     

**이것을 이제 celery-beat이용해서 해볼까? 그전에 TIL에 정리중인거 보자.**   
celery-beat, celry 뭐가 다른가?

**celery**
>알다시피 사용자 요청 --->응답 돌려주는 시간 오래걸려서 사용자 대기해야 될때 일단
사용자에게 요청 완료됬다 보내고 실제 요청을 worker이용해서 뒤에서 비동기적으로 수행하는것.

**cerlry-beat**
>주기적으로 월간 방문자계산 같은 작업 할때도 celery work시켜서 비동기적으로(백그>라운드에서)이를 처리할 수 있는데 작업큐(taskque)에(우리같은경우는 redis쓸꺼다.) 주기적으로 필요한 작업을 넣어주면 되는데 이역할을 하는것이 celery에 포함된 beat>이다.  

**여기서 질문**
일반적인 celery기능과(바로 worker에게 일 분할해 시키는것)       
beat(스케줄러) 같이 쓸 수 있을까?     
예를들어 celery가 task받으면 beat에 일단 추가하는데 이     
baet에 이미 1시간 뒤에 뭔가 실행하시오라는 문장이 있고    
이번에 추가하는것은 바로 실행하시오~라는 문장을 추가하는것이라서     
바로 실행된다~~ 가 맞는것일까?  (아래 글읽고 정리한거 봐라.)       

**celeryd, celery worker, celerybeat차이점은?**   
`celeryd` 는 celery worker명령어의 오래전 이름( 우린 예전에 데몬으로 돌리기위해   init/celeryd포함해주기도했다.)  
`celerybeat` 주어진 시간에 미리 정의된 task를 celery worker에게 전달한다.   

[글1](http://i5on9i.blogspot.com/2016/07/celery_21.html), [글2](http://docs.celeryproject.org/en/master/userguide/daemonizing.html#init-script-celerybeat)  참고중이다.     


위에 두 글 정리해보면  
1. `celerybeat`(스케줄러) 에 정의된 `task`가 정해진 time되면 
   -> redis(broker) 의  que에 쌓이고 `celery-worker`에게  `redis`가 알맞게 분배한다.  

2. 워커 한개 실행시.  
    ```
    proj> celery -A proj worker -l info
    proj> celery -A proj beat -l inf
    ```
3. 워커 여러개 실행시. 
     redis(broker) que와  celery-worker의 관계는 다음과 같이 settings에 정의후 
     그 큐 사용하는 워커 실행할 수있다. 
     이렇게하면 30초에 한번씩? 워커가 que의 변동사항을 체크한다고 한다.  
    ```
    1) CELERY_ROUTE로 taks 가 어떤 queue 사용할 지 정함. 
    CELERY_ROUTES = {'pworker.tasks.import_feed': {'queue': 'feeds'}}  
        (imported_feed라는 tasks가 feeds라는 que에서 메시지받아 처리하도록함.)
    
    2)feeds라는 이름의 queue를 처리하는 worker를 실행.  
    celery -A proj worker -Q feeds(que이름 이렇게 지정)  
     ```  
    (celery beat에는 보통 tasks.feeds 같이 어떤  tasks 를 que에 넣을지 정의되있음 - 
    que-worker관계 자체는 위에 말한거처럼 CELERY_ROUTES에 써짐. 
    하지만 바로 어떤 que에 늘지 celery beat에서 위에 글처럼 명시가능하다.)  
    
근데이글들 오래된거라서...신뢰안된다... 하나더찾아보자.    

