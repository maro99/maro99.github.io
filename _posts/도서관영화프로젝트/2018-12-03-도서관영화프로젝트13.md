---
layout: "post"
title: "도서관영화프로젝트13"    
categories:  
- 도서관영화프로젝트      
tags:  
- 일지      
- celery   
- init.d   
- redis  
- caching  
comments : true    
date: "2018-12-03 18:50"  
---           
# Celery& Redis를 사용한 TaskQueue 시스템 구현 Redis 서버로 ElasticCache 사용  


---



##  1. celery 기본개념 상기해보자.    

**celery??**  
만명에게 메일일 동시에 보내고 싶다면? 셀러리 에게 메일을 만개 보내야된다고날림.   
셀러리가 만개 작업 가지고 작업자 들에게 뿌림.   
일반적으로 cpu 코어수 대로 하는 것이 유리하다.  

---> 웹에선 리퀘스트오고 리스폰스 로 돌리는데...     
뷰 함수에서 하는게 많으면 사용자가 답답하다.  
링크 클릭후 시간 많이 걸리면 답답함.  
   
이렇게 오래걸리는 작업들은 백그라운드에서 도는 셀러리에게 맞긴다.   
( 페이지에서는 곧 메일이 갑니다 라고 뜨고.)    

```
Celery
python application1 - Brokser  - Workers -(W1,W2,W3,W4,W5)          -
python application2    Queue
                        Task1
                        Task2
                        Task3
                        Task4
                    RabbitMQ  - EC2
                    Reddis
```  

Reddis(캐시 서비스 . AWS에서는 공짜로 제공,) AWS ElasticCashe   
-------> ( 로컬에선 안되고 실제 aws로 배포하는 환경에서만 적용)   

**캐시**  
메모리에 자주쓰는 것을 미리 복사해놓는  임시 장소.  
하드디스크 - ssd 상에 존재하는 데이터를 메모리상에 가져다 놓는것.  
db에서 데이터 가져오는것 가장 느리다.    

이런 케시도 따로 서버 형태로 존재한다.  
( 웹서버의 응답은 메모리에 캐싱되는데 어플리케이션의 캐시는 로컬 혹은 캐시서버위에   Fr실행되는 인메모리 데이터베이스 에 저장될 수 있다. )  
  
aws elasticcahe ----> `redis`, `memcached` 제공한다.    
(장고에서는 `Memcached` 자주씀...-->장고 하나로 app만들때,편함    
오래걸리는 쿼리 이걸로 쓰면 최적화 좋을것임.)  
(필요한 값들 미리 메모리에 넣어놓고 메모리있으면 거기서 가져오고   
없으면 메모리를 미리 케싱해놓고 가져오는 작업 쉽게 쓸 수 있다. )  

**왜 실제서버와 (ec2와)  캐시서버  분리되야 할까?**
`python application`이`elascitbeanstalk`안의  `ec2`안에서 돌아가면   
언제든지  `AutoScaling`의해서 없어지고 생길수 있다.
이 `python application` 사라지는것 자체는 크게 상관없다. 
그런데 `pythonapplication1` 이 task 200개를 `broker`에게 맞겼다고 가정해보자. 
이 `broker`가 `pythonapplication`과 같은 `ec2`에 있었다면 
(사용자 유입이 줄어서 ) `autoscaling`의해서 `ec2`, `pytho applicatoin`  
사라지면 거기에 맞긴 `task` 200개 다 사라진다.
-> 그래서 `Broker` 서버(케시서버) 따로 놓는다.  
(마치 rds처럼 하나의 역할을 하는 서버가 있는것.)  

`RabbitMQ `서비스를 브로커 사용시엔  세로운`EC2` 만들어서 `EC2`안예    
`rabit mq`라는 서비스를 깔아서 
요청을 받고 내보내는 서버를 만들어야 한다 
(마치 RDS스스로 만드는 것과 같다. -   
RDS 경우 데이터 받아서 DB예 서빙하는데 특화된 서버-ec2만들고 db거기깔아서 외부포트 연결   하면  같은 역할 한다.  근데 보통 이런걸 많이 쓰고 사람들 실수 덜기위해 RDS라는 서비스를   만든것. )  

`Redis` 서비스를 브로커로 사용시엔  `AWS ElasticCache` 서버를 둔다.  
(마찬가지로 cache 서버 두는것 개발자들에게 귀찮아서 이런 서비스 쓰는것.)
브로커로 `Redis`라는 케시 시스템을 쓸 수 있는것. 
이 케시서버에 task가 기록되고 브로커로부터 `worker`로 전달된다.   
(worker는  python application이 있는 ec2안에서  같이 존재한다. ---  
결국 워커가 하는 작업 가져다 쓰는 함수 등은 python application이 가지고 있어서 )  
적어도 이것이 도는동안에 하나의 task 시작후 끝나기 전에 ec2 끝내지는 않으니 안심해라.)  

---   




## 전체 방향 다음과 같이 정해봤다.     

0. Django에서 Redis를 이용해 Caching하기 `이 페이지에서는 이항목 주로 다뤘다.`

1. celery-reids로 local 환경에서 email_sand task

2. celery+redis로 local환경에서 celery-beat 이용 특정 task 를 que에 넣고   
   정해진 task 알맞은 시간에 수행

3. celery+redis로 local 환경에서 celery-beat -> 특정task que에 넣고 정해진task 알맞은
   시간에 수행, celery-worker 그때그때 유저 요청시 email-send해주기

4. 이거보고 [공식문서](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#generic-initd-celerybeat-example) celery-beat 를 init-script  데몬으로돌리던거   
    예전에  celery-worker init.d에 넣어서 실행시키던거     
    [이거](https://www.evernote.com/client/web#?anb=true&b=1917b08f-9255-4138-9cc4-fa196bcd2155&fs=true&n=fb0b1c85-09eb-437b-8f15-15ef1521d68d&s=s372&)   redis서버 background도는 예제 stackoverflow  찾아서 2번 3번 해보자.    
    (가능하면 모두 init.d에 일괄적으로 넣어서 해보고 싶다.)
              
5. docker에 넣고 해보기   
    ( 4번 잘 안되면 여기 넘어와서 dev모드에서 docker안에서  이 셋을 supervisor로 실행시키기)

6. celery-redis로 production에서 elasticcahe사용, 1번 -> 3 번 구현하기

7. 내프로젝트에 완전 적용  
    소셜로긴, 일반로긴 시 전화번호 받도록 해놓고  
    일반로긴시는 (sms인증 or email인증 중 선택할수 있도록.)  
    특정 시간에 sms 알람 해보고 --->  
    사용자에게 해당 날짜 다가오면 그날 task-que에 알림 쌓아놓고 차례로 보내기.  


---  




 
### 0) Django에서 Redis를 이용해 Caching하기   
 
 가장먼저 민규님이 보내주신것 보고 해봤다.
 [Django에서 Redis를 이용해 Caching하기](https://www.google.co.kr/amp/s/jupiny.com/2018/02/27/caching-using-redis-on-django/amp/)  
   
 다음 명령어들 주로 사용했다.      
`sudo apt-get install redis-tools`  
`sudo apt-get install redis-server`  
`ps -ef | grep redis`(런서버하면 한줄 늘어나네 ? )      

**내가 이해한 바를 정리해보면**  
일단 처음에는  `loadtest`라는 친구는 어떤 페이지에 n개의 요청 보내면   
시간이 얼마나 걸리는지 성능을 측정해주는 애이다.     
우리는 캐시를 써서 이 속도를 단축시키고 싶다는 것인데    
`redis`를 `cache`로 사용해서 이를 해결하려 한다.  

이전에 했던 `celery`이용한 처리 참고하면 
```
셀러리는 일꾼으로 해야할일 처리, ------------->처리할 일 큐에 쌓아놓고 일꾼들이 가져다 일함.
redis, rabitmq는 주인, 메시지 브로커를 담당한다. ------>실제 컴퓨터 메모리를 이용한 케쉬, 
                                                        키와 벨류값을 이용해 처리할 작업을 celery에 보낸다음 
                                                        캐쉬 시스템 에서 해당키를 없애는 방식으로 동작   
```
장점은 db사이에서 자료 왔다갔다 하는것보다 메모리에서 케쉬 가져다 쓰는것이 빠르다는것.   
특정데이터 반복적으로 빈번하게 돌려줘야한다면 메모리 캐쉬를 사용하면 좋다.    

(근데 뭔가 셀러리의 워커같이 직접적으로 일해주는애가 있어야지 웹페이지 보여주는것을   먼저하고 처리를  뒤에서 하고 아닌가?   
캐쉬 자체만 있는데 어떻게 시간이 줄어드나?  )   



**실질적으로 해본것**   

서버 키고    
특정 `adreess` 접속시 모든 ~개의 post오브잭트들을 보여주도록 했었다.   

그뒤 이 post오브젝트 모두 보여주는 `my_view`를   
`posts = Post.objects.all().values('id', 'text')` 에서     
`posts = cache.get_or_set('posts', Post.objects.all().values('id', 'text'))` 이렇게 케쉬의  
함수 `get_or_set`을 사용하는것으로 바꿨다.   
(내생각에는 이것이 초기에는 set해서 posts란 키값으로 캐쉬에 넣고 그다음엔 get해서 캐쉬로부터 빠르게 꺼내오도록 한것같다.)    
  
그뒤 다시 런서버를 하고     
`curl http://localhost:8000` 이걸로 요청을 한개 보내니 캐시서버에 키가 생겼다.   
즉 캐시서버에 키형태로 저장된것인가보다.    
`redis-cli -h 127.0.0.1 -p 6379` 이렇게 레디스 캐시 서버에 들어가서 보니     
`":1:posts" `라는 키가 잘 생겼다.   
  
그리고 캐쉬서버 이용해서 실제 작업   
아까 `loadtest`이용해서 `http://localhost:8000 `에 요청 100개 보내   
태스트 해보던것 을 다시 해보니 
`loadtest -n 100 http://localhost:8000`

시간이 확실히 10초나 줄었다.   


**잠깐~ 왜 케시 쓰는지 보고가자.**   
캐시라는것이 디비에 접속 일일이 안하고 ram에 디비에서쓸것 미리 저장해놔서  
접근 빠르게 하겠다~이런거 아닌가?  
좀 찾아보자.  
[[번역] 웹 캐싱의 숨겨진 요소](https://mingrammer.com/translation-the-hidden-components-of-web-caching/)들 이거 보는중.   

```
캐싱(Caching)은 애플리케이션의 처리 속도를 높여준다. 이미 가져온 데이터나 계산된 결과값의   복사본을 저장함으로써 처리 속도를 향상시키며, 이를 통해 향후 요청을 더 빠르게 처리  

웹 서버는 응답을 캐싱하도록 구성할 수 있어 유사한 요청이 애플리케이션 호스트로 전달되지   않도록 할 수 있다. 이와 유사하게, 애플리케이션 호스트는 비용이 높은 데이터베이스 쿼리나   자주 요청되는 파일들에 대한 응답의 일부를 캐시할 수 있다.   
웹 서버의 응답은 메모리에 캐싱된다. 애플리케이션 캐시는 로컬 인메모리에 저장되거나 캐시   서버 위에서 실행되는 레디스와 같은 인메모리 데이터베이스에 저장할 수 있다  
```  
 
**갑자기든 의문**   
 뭐 포스트에  대한 데이터를 저장해놨다가 빠르게 가져오는것은 그렇다쳐도 ...  
메일 보내는 작업을(그때 tasks.py의 내용) 케쉬에 가지고 있는것은 어떤 의미인지?    
이걸 궂이 캐쉬에 가지고 있을 필요가 있나? 어짜피 일은 워커가 하는데요?   
우리가필요한건 일처리하는 시간을 줄이는거지 데이터 가져오는걸 줄이는게 아닌데    
무식하게 디비에 뭔가 저장된다고 해결되나?    
(아니면 함수에 쓰이는 어떤 데이터들을 미리 가지고 있기에 빨라진다는 의미인가?)     

아래 경영학도님 글보면   
```
Redis는 실제 컴퓨터 메모리를 이용한 캐쉬다. Key와 Value값을 이용해 처리할 작업을 Celery에게 보낸 다음 캐쉬 시스템에서 해당 키를 없애는 방식으로 동작한다.
```
이렇게 되있는데 캐시서버가 그냥 내가 생각한거처럼   
앞으로 해야되는일, 자주하는 일들을 que에 저장해놓고 clelery가 가져다 써야되는데   
그 que를 저장하는 공간.(같은내용 자주 불러쓰니까) 이 되는것같다.  
서버로 따로 만든이유는  앞서  말했듯이 ec2따운되면 캐쉬들도 따운되서   
요청한 작업(이메일 특정 유저에게 보내기) 등이 사라져버려서.  

redis는 rabitmq와 달리  뭔가 캐쉬같은 성격이 있는건가?  --->아래 보니 그렇다.   

**redis, rabitmq차이점 정리**     

먼저 모르는 용어 두개 찾아봤다.      
**비관계형 데이터 베이스** -  키,값 데이터베이스모델 사용 . 즉 분할성 커서 넓은 범위       수평확장.  ---> 게임 iot적합. 지연시간 일관되게 작다.      
**인 메모리**- 게이밍, 광고기술 엡에는 밀리초의 응답시간 필요.  디스크 기반 db에서는   불가능하다. 서비스지연 적다.  (메인메모리 사용)      
```
<redis> 
Remote Dictionary Server.
위키 -> 키-값 구조의 데이터를 관리하기 위한 비관계형  인 메모리 DBMS,이다.(메인메모리 사용.)          
              (1. 데이터 디스크에 안들어가고 메모리에 저장되서 빠르고, 
                2. 장비죽으면 데이터 사라지지않는다? ( 이게 memcache랑 다른점. + 디스크에도 저장하는듯.)
                3 . 만료되면 자동으로 데이터 사라지며  (만료일 지정 안하면 안사라짐.) 
                4. 저장소 메모리 재사용 x --> 명시적으로만 데이터 제거 가능. (멤케시는 부족하면 지우는듯.)
                5. 다양한 종류 추상데이터 제공( 역시 , 멤케시랑 다름. )

윗글 - > 메시지브로커, 데이터베이스 및 캐시 역할을 모두 수행할 수 있는 오픈소스 인메모리(DBMS)데이터 자장소이다.  
              다양한 종류의 추상 데이터(string,list,map)을 지원한다.  

<Rabbitmq>
오픈소스 메시지 브로커 
RabbitMQ는 고도로 중앙 집중화된 분산형 시스템의 구현에서 중요하다 여러 메시징 프로토콜을 지원합니다.
```    
 윗글비교 보니 간단한 작은 양의 메시지는 redis나쁘지 않고      
 키- 값구조 데이터 관리하기 적합하다.  하지만 대용량 메시지는 rabbitmq적합한듯.     
 
**Redis와 elasitcache는 어떤 관계인가?**  
[AWS 문서](https://aws.amazon.com/ko/nosql/ )  의 다음 문장을 보면   
```
Amazon ElastiCache는 Memcached 및 Redis를 통해 디스크 기반 데이터 스토어에서는 불가능한   서비스인 지연 시간은 적고, 처리량은 높은McDonald’s 같은 워크로드를 제공  
```
elasticcache는 아마존에서 제공하는 RDS같이 사용자가 쓰기 쉽게 만든 서비스 인데    
Redis를 미리 ec2하나에 설정해 놓고 이것을 캐시서버로 편리하게 쓸수 있도록 만들어   놓은것인듯. + redis원래 속성 따라서 메시지 브로커로서도 쓸수 있는듯.    

 (혹은  경영학도님이 말한 ~ 처리할작업을 셀러리에 보내고 캐시 시스템에서 해당키 없에는 방식으로 동작해 본다~에서 유추해보면      
 그냥 캐쉬 서버 역할도 하지만, 메시지브로커<어플리케이션 -장고 에서 task받아서 celey의 worker에 task배분해주는> 로써 redis가 쓰일때는 그런 task분배 빠르게 하기 위해  캐시   데이터베이스 의 성격이 빛을 발하는듯.(그냥 일반적인 디비랑달리 캐시디비이고, 능동적으로   들어오는 요청을 나눠서 제 3자에게 분배 가능한듯.)   
 
 **그래서 우리가 rabbitmq안쓰고  redis쓰는 이유는?**    
 rabbitmq보다 inmemory에 저장하는 캐쉬디비 사용하는 메시지 브로커 기능 가능해서빠르고,   이미 아마존에서 elasticcache에 서비스를 만들어놔서 가져다쓰기만 하면 되니까.      
 
 
 **질문 한개더.  in-memory database랑 inmemory cache랑 다른점은?**
redis는 캐시 인지 디비인지? (캐시이다!) 
[이글](https://stackoverflow.com/questions/37015827/difference-between-in-memory-cache-and-in-memory-database)참조 .    
디비는 기본적으로  보안성이 높고,(디비복제 못하도록)    
캐시와 달리 정보의 지속성 추구한다. ( 캐시는 보통 파워나가면 지워짐)    
하지만 redis처럼  정보 지속성 가진 (래디스 경우 유통기한설정안해주면 지속 가능) 캐시와   immemory database사이 구분이 모호하긴 하다.     


### 정보는 이정도 찾아봤고 다시 하던거 보자.   
[이글](https://jupiny.com/2018/02/27/caching-using-redis-on-django/) 참고중이다.    

Caching구현 끝난게 아님. 
이렇게만하면 `Redis`의` TTL`(정보의 유통기한)만료될 때 까지 `get_or_create`기 때문에    `post` 객체들이 추가되거나 수정되어도 기존에 `post(키) : post객체 정보들` 이렇게 되있는 캐시의 정보가 안바뀌고 사용자는 같은 데이터만 전달받게 된다.     

---> 따라서 DB의 데이터가 변경될 때마다 `Cach`를 초기화 해야한다. 
이런걸 **오버헤드라** 한다.  읽기 작업보다 쓰기(오버헤드) 가 빈번해지면  
**Caching성능이 저해**된다.       

아래와 같이 `Post`모델의 `save()`, `delete()`함수를 `overide`해서 구현한다.      
```
# models.py

from django.db import models  
from django.core.cache import cache


class Post(models.Model):  
    ... # 생략
    def save(self, *args, **kwargs):
        cache.delete('posts')
        super().save(*args, **kwargs)

    def delete(self, *args, **kwargs):
        cache.delete('posts')
        super().delete(*args, **kwargs)
```  

이제 post모델의 인스턴스를 생성,변경, 삭제 하면 Redis에 저장됬던 키값이 제거될 것이다.    
(그래서 그다음번 localhost접속시 기존의 redis안의 'posts'키 사라졌기 때문에 get못하고  
 새로 'post'키를 create하고 객체들 정보를 같이 넣어주게 되어서 최신 정보가 redis안에   들어가게 된 것.)    





 
