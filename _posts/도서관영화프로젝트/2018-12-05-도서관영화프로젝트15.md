---
layout: "post"
title: "도서관영화프로젝트15"    
categories:  
- 도서관영화프로젝트      
tags:  
- 일지      
- celery   
- init.d   
- redis  
- caching  
comments : true    
date: "2018-12-05 18:50"  
---              

# Celery& Redis를 사용한 TaskQueue 시스템 구현 Redis 서버로 ElasticCache 사용     


---   


## 목차     

0. [Django에서 Redis를 이용해 Caching하기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/03/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B813.html) `12.03 완료`  

1. [celery-reids로 local 환경에서 email_sand task](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/04/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B814.html)   `12.04 완료` 

2. celery+redis로 local환경에서 celery-beat 이용 특정 task 를 que에 넣고 
  정해진 task 알맞은 시간에 수행    `이 페이지에서는 이항목과`

3. celery+redis로 local 환경에서 celery-beat -> 특정task que에 넣고 정해진task >알맞은
  시간에 수행, celery-worker 그때그때 유저 요청시 email-send해주기  `이항목 주로 다뤘다.`

4. 이거보고 [공식문서](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#generic-initd-celerybeat-example) celery-beat 를 init-script  데몬으로
돌리던거
   예전에  celery-worker init.d에 넣어서 실행시키던거
   [이거](https://www.evernote.com/client/web#?anb=true&b=1917b08f-9255-4138-9cc4-fa196bcd2155&fs=true&n=fb0b1c85-09eb-437b-8f15-15ef1521d68d&s=s372&)   redis>서버 background도는 예제 stackoverflow  찾아서 2번 3번 해보자.
   (가능하면 모두 init.d에 일괄적으로 넣어서 해보고 싶다.)

5. docker에 넣고 해보기
   ( 4번 잘 안되면 여기 넘어와서 dev모드에서 docker안에서  이 셋을 supervisor로
실행시키기)

6. celery-redis로 production에서 elasticcahe사용, 1번 -> 3 번 구현하기

7. 내프로젝트에 완전 적용
   소셜로긴, 일반로긴 시 전화번호 받도록 해놓고
   일반로긴시는 (sms인증 or email인증 중 선택할수 있도록.)
   특정 시간에 sms 알람 해보고 --->
   사용자에게 해당 날짜 다가오면 그날 task-que에 알림 쌓아놓고 차례로 보내기.  



---   
이거보고 [공식문서](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#generic-initd-celerybeat-example)`celery-beat` 를 `init-script`  데몬으로돌리던거  + 예전에    `celery-worker init.d`에 넣어서 실행시키던거  [이거](https://www.evernote.com/client/web#?anb=true&b=1917b08f-9255-4138-9cc4-fa196bcd2155&fs=true&n=fb0b1c85-09eb-437b-8f15-15ef1521d68d&s=s372&)      
`redis`서버 background도는 예제 [stackoverflow](https://www.techietown.info/2017/03/how-to-start-redis-in-background/)  찾아서 2번 3번 해보자.  
(가능하면 모두 init.d에 일괄적으로 넣어서 해보고 싶다.)

혹은 dev모드에서 `docker`안에서  이 셋을 `supervisor`로 실행시키기   


## 2. celery+redis로 local환경에서 celery-beat 이용 특정 task 를 que에 넣고 정해진 task 알맞은 시간에 수행        

다음은 [여기](http://wangin9.tistory.com/entry/celery) 에서 퍼온 글이다. 참고로 적어놓음   
 `pip install django-celery-beat`
` pip install django-celery-results`

**config.settings**

```
INSTALLED_APPS = [
      'django_celery_beat',
    'django_celery_results',
```
```
# Celery
CELERY_BROKER_URL = 'redis://localhost:6379'
CELERY_RESULT_BACKEND = 'redis://localhost:6379'
CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TAST_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Asia/Seoul' #Celery beat가 스케줄러이기 때문에 시간에 대한 정의를 해야
```

**tasks.py**  
```
from __future__ import absolute_import, unicode_literals
import random
from celery.decorators import task

@task(name="sum_two_numbers")
def add(x, y):
    return x + y
 
@task(name="multiply_two_numbers")
def mul(x, y):
    total = x * (y * random.randint(3, 100))
    return total
 
@task(name="sum_list_numbers")
def xsum(numbers):
    return sum(numbers)
```  

`python manage.py makemigrations`
`python manage.py migrate`

**Celery 서버를 실행해보자**  
`$ celery -A   [파일이름]   worker -l info`

**Schedule 을 작성해서 task를 실행**

```
from celery.schedules import crontab
 
@app.task(bind=True)
def debug_task(self):
    print('Request: {0!r}'.format(self.request))
 
app.conf.beat_schedule = {
    'add-every-minute-contrab': {
        'task': 'multiply_two_numbers',
        'schedule': crontab(), # 1분마다
        'args': (16, 16),
    },
    'add-every-5-seconds': {
        'task': 'multiply_two_numbers',
        'schedule': 5.0, # 5초마다
        'args': (16, 16)
    },
    'add-every-30-seconds': {
        'task': 'tasks.add',
        'schedule': 30.0, # 30초마다
        'args': (16, 16)
    },
}
```   
### 위 코드들 참고해서 따라해봄.   

`celery -A config  worker -l info`  
`celery -A config  beat -l info`  



```
return iter(x.items())
AttributeError: 'float' object has no attribute 'items'
```
다음과같은 애러뜬다....
  
redis버전 낮춰줌   
`pipenv uninstlal redis  `
`pip install redis==2.10.6  `  

redis안의 냬용 `reset`
   
`redis-cli flushall`  
  
기존 pipenv install "celery[redis]' 이렇게 의존성 페키지 다깔았는데 
redis버전 낮춰야 하니까      
celery깔고 redis버전 낮춰서 깔고 각각 해줘야 할듯.      
   

근데 잘보면 또 애러뜬다.   
```
[2018-12-06 04:24:30,526: ERROR/MainProcess] Received unregistered task of type 'config.tasks.add'.
The message has been ignored and discarded.   
```   
->이런식으로 scheduler에서 task참조하는거 일단 지우고 다른방식처럼  name으로 참조하게했음.

확인결과 애러없이 잘 됬다.

---




## 3. celery+redis로 local 환경에서 celery-beat -> 특정task que에 넣고 정해진task 알맞은 시간에 수행, celery-worker 그때그때 유저 요청시 email-send해주기      
위  상황에서 `email send` 해보니 `redids` 해당 `celery_broker_url`의 storage(que)에     `message`쌓이고 `email send`까지 처리되는 거 볼 수 있었다.     

