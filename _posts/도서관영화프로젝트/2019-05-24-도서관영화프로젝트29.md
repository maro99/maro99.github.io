---
layout: "post"
title: "도서관영화프로젝트29(작성중)"
categories:
- 도서관영화프로젝트
tags:
- 일지
- ci
- deploy
comments : true
date: "2019-05-24 18:50"
---       

커밋단위 테스트 배포와, 무중단 배포를 어떻게 동시에 할지 고민을 해봤는데    
당장 아는것이 하나도 없어서 **cI를 사용한 커밋단위 테스트 배포, 머지 자동화**     
관련해서 모르는 것들을 하나씩 일단 해보려고 한다. 

해보려는 것들의 순서는 다음과 같다.    
0. 파이썬으로 travis시작하기. 
1. yapen_new에서 한번 travis+ eb 연결
2. travis + eb에서  before deploy에서  git clone 프론트 엔드 해오는것이 가능한지? 
3. eb cli 로 환경 생성 및 삭제   
4. eb cli로 green 환경 생성 -> cname swap 으로 green환경으로 트레픽 이동 ->    
   (blue환경 새로운것 배포, 및 테스트)  -> 성공시 cname swap
5. 람다에서 cron써서 travis + eb 주기적으로 최신 코드 test및 deploy하게 해보자. (or + cloud watch) 
 6. travis cron + eb 로 주기적으로  최신코드 test및 deploy 하게 해보자. 
7.  AWS로 배포하기 1,2,3 codebuild, code deploy, code pipeline설명보고 따라하고, 정보 수집.  
 8. AWS 블루그린 배포 (code pipeline, lambda, codebuild , eb, s3 ) 참고서보고 그대로 해보기.
 9. code deploy  & ec2 & docker 


---    


####  파이썬으로 travis시작하기. 
[공식문서](https://docs.travis-ci.com/user/languages/python/)        


.travis.yml 
```
language: python
python:
    - "3.6.5"


install:
    - pip install -r requirements.txt


script:
    - python app/manage.py test
```   
requriements.txt 추가해주고 git push 해서 하니까 안된다..

[에러 내용]   
```
-3.6.5 is not installed; attempting download
Downloading archive: https://storage.googleapis.com/travis-ci-language-archives/python/binaries/ubuntu/14.04/x86_64/python--3.6.5.tar.bz2
$ curl -sSf -o python--"3.6.5".tar.bz2 ${archive_url}
curl: (22) The requested URL returned error: 404 Not Found
```
---> 띄어 쓰기 잘 넣어서 해결 (위에  수정해놨음 )        
   
새로운 애러  발생     

[에러내용]    
```
raise ImproperlyConfigured("The SECRET_KEY setting must not be empty.")
django.core.exceptions.ImproperlyConfigured: The SECRET_KEY setting must not be empty.
The command "python app/manage.py test" exited with 1.
```

해결방법 찾은것. 
[이 블로그](https://rainsound-k.github.io/deploy/2018/05/14/django-travis-ci.html)(보면 secret을 zip으로 암호화 해서 올린다.)   

```
6. SECRET_KEY 에러 해결

SECRET_KEY 값을 참조할 수 있도록 .secrets 폴더를 압축 -> 암호화 -> 업로드 -> 복호화 -> 압축해제 하는 방법으로 에러를 해결해보겠습니다.

    6.1 .secrets 폴더 압축
    아래 명령어로 .secrets 폴더를 .secrets.tar 파일로 압축해줍니다.
    $ tar -cvf secrets.tar .secrets
 
    6.2 .secrets.tar 파일 암호화
        터미널에 travis를 설치
        $ gem install travis
        (위의 gem 명령어가 안 먹힌다면 ruby를 설치해주세요!)
        
        터미널에 travis 로그인
        $ travis login
        (Username은 github의 Username 입니다.)
        
        암호화
        $ travis encrypt-file secrets.tar --add
 
    6.3 gitignore에 secrets.tar 파일 추가

    위의 과정을 마치면 secrets.tar, secrets.tar.enc 파일이 프로젝트 폴더에 생긴 것을 확인할 수 있습니다. 
    secrets.tar 파일은 github에 올라가면 안되므로 gitignore에 추가해줍니다.
    # Custom
    /.secrets
    secrets.tar
    ...
 
    6.4 .travis.yml에 압축해제 명령어 추가
    .travis.yml 파일을 다시 열어보면, 아래처럼 before_install에 명령어가 자동으로 추가된 것을 확인할 수 있습니다. 이는 travis에 코드를 올리면 secrets.tar.enc 파일을 secrets.tar파일로 복호화 하라는 명령어입니다. 하지만 파일을 복호화한다해도 여전히 압축파일로 남아있기 때문에, 압축해제 명령어를 before_install에 추가해줍니다.
    before_install:
    ...
    - tar xvf secrets.tar
    



    7. 최종 확인
    모든 준비는 끝났습니다. 이제 github에 push 했을때 에러가 발생 안하는지 확인하면 됩니다. 아래 명령어로 다시 push 해주고 에러 없는 것을 확인하면 끝입니다!
    $ git add .
    $ git commit -m '~~~'
    $ git push -u origin master
```

위 과정으로 해결 후에 
django 환경변수 export도 해줬다.  

production으로 export해서인지 이런 애러 뜸.  
[애러내용]   
```
connect
conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
django.db.utils.OperationalError: could not connect to server: Connection timed out
    Is the server running on host "eb-docker.c0afkt97bzcd.ap-northeast-2.rds.amazonaws.com" (52.78.187.218) and accepting
    TCP/IP connections on port 5432?
 
The command "python app/manage.py test" exited with 1.
```

-> export할때 local로 하니까 pass잘됬음.


**[질문]** 
master브렌치로 지금 달아놨으니까  이게 deploy된다면 master에 되는건데 
그렇다면 production을 export해서 production환경을 테스트하는게 맞지 않나?    

travis에서 브렌치 설정하는 항목이 있던거 같은데 
그렇다면 local, dev , production 다 테스트 할수있는거 아닌가?     

내생각엔 두가지경우  가능한것 같다. 
```
1.dev 환경 -> dev 환경변수 export해서 테스트 후 (dev에 맞는 웹에 배포  -> production도 따로 태스트후 따로 배포 )
                                            or (dev는 베포 안하고 테스트만 통과(commit만 된상태 ) -> production는  테스트후 master에 배포 )   
2.production환경 - > productino환경 테스트후 배포.
```

**[질문]**  
머지 자동화는 그럼 뭐지?    
추측은 이거다. 
dev 브렌치 를 travis랑 연결 해서 테스트를 통과시에 
master 브렌치 로 머지 따로 시켜줌. 
이후 master브렌치를 배포. 
어떻게 할지 각이 살짝 나옴.  
berfore_install, after_install -> script에서 테스트  -> before_deploy, after_deploy   
이런 순서인데
태스트 까지는 dev에서 하고 before_deploy에서 master에 머지 해주고   
배포는 production master에 서 해주면 될듯 (여기 yml참고) 

production, dev를 export했을때 기본 파이썬 test되도록 한번 해보자. 
db설정을 어딘가에서 해주면 될것이다.  
 
**[질문]**  
tarvis에서 script에서 `python manage.py test`이렇게 해서 테스트 하는데   
우리가 테스트 하려는 이유가 푸쉬 -> 테스트 자동으로 실행하고 -> 배포까지.       
이것때문에 하는것을텐데. 이거 그냥 자신의 컴퓨터에서 스크립트 짜놓으면 되는거 아닌가?  
왜 궂이 웹에 있는 travis에서 빌드하고 테스트하라는 명령어를 웹에서 실행하나?    

답변:  
서버 개발자인 내 입장에서는    
프로젝트 전체가지고 있고 테스트 코드 돌리고 하는것이 그냥 바로할수 있겠지만     
다른 팀원들 입장에서는 테스트 코드 자체 몰라도 되고 그냥 푸쉬해서 테스트 통과시 자동으로   
배포 까지 되도록 하고싶은것.   
하지만 **각 커밋 또는 병합(each commit or merge) 전에 테스트를 실행하는 것을 기억하는 것은  
수동으로 해야한다면 힘들수 있다.  
CI는, 변경사항이 커밋되어졌을때 자동으로 빌드와 실행을 처리** 한다.  

**빌드하는것의 의미는?** 
그냥 python test를 실행 하기 위한 의미인가? ->테스트 자체는 코드만 있어도 될듯?  
아니면 s3형태로 만들어서 테스트 통과시 바로 zip이용해서 배포  하기위한것인가      
(근데  그렇게 보기엔 s3에는 위에 테스트 local했을때  아무것도 안올라갔다.) 
-->
새로운 소스 코드로 배포가 이루어지기 전엔 빌드라는 과정을 거친다.   
그런데 사실 파이썬은 컴파일 언어도 아니고, 
뭐 따로 패키징하고 그런 작업도 없기 때문에 빌드라는 단어는 별로 어울리지 않는 것 같다고   
생각했는데, 그냥 **'배포 전처리 과정'을 빌드라고 관례적으로 이야기***하는듯

[이글](https://jojoldu.tistory.com/265)의  초기 test후 s3에 deploy하는 과정 보면 빌드 결과는 test이후에    
어쨌든 테스트 대상에 대해서 생기고 이걸 deploy해야 올라가는듯. 

![](https://imgur.com/HPbijb9.png)



**[질문]**  
우리 그냥 함수들을 테스트 하는것이 문제가 아니라        
docker nginx,uwsgi, celelry,redis,supervisor 등이 잘 동작하고 있는지 테스트    해보려는것인데.    
docker 내부에서 test안하고   
현재는      

requriements.txt.만들고 그것 보고 페키지들 받아서 현제 그냥 로컬에서    
pipenv shell이후 프로젝트 charm으로 킨거랑 같은 상태에서   
python manage.py test한것인데   
이게 의미가 있나?    

전체 시스템이 잘 동작하는지 테스트를 해보는 것이라면   
dev를 test해본다면 
[여기](https://akhil.work/docker-reactjs-github-travis-ci-aws-part-4/) 처럼    
```
#Tell Travis that we need super user permissions
sudo: required
services:
#Tell Travis that we need docker
  - docker
 
#Tell Travis that before executing the script, create the docker image from the DevDockerfile.
before_install:
  - docker build -t akhil/docker-react-aws -f Dockerfile.dev .
 
#Tell Travis to execute tests (-- -- Coverage will exit npm run test and print out the code coverage)
script:
  - docker run akhil/docker-react-aws npm run test -- --coverage
 
deploy:
  #specify the provider
  provider: elasticbeanstalk
  #specify the region where the provider is present, You can get this from the AWS ElasticBeanstalk dashboard
  region: "us-east-2"
  #Specify the application name in AWS elastic beanstalk
  app: "docker-react-aws"
  #Specify the environment name in AWS elastic beanstalk
  env: "DockerReactAws-env"
  #Specify the Bucket name which is the name of the S3 (storage) which is created as part of Elastic beanstalk in AWS
  bucket_name: "elasticbeanstalk-us-east-2-310307354087"
  #specify the path of the Bucket , this will be similar to the App name above
  bucket_path: "docker-react-aws"
  #specify when you want to deploy (we want to deploy only when we push code to master branch)
  on:
    branch: master
  #Specify the Environment variable name from which Travis can get the ACCESS_KEY to AWS
  access_key_id: $AWS_ACCESS_KEY
  #Specify the Environment variable name from which Travis can get the SECRET_KEY to AWS
  secret_access_key:
    secure: "$AWS_SECRET_KEY"
```
before install에서  dockerflile.dev를 빌드하고   
script에서  docker run 하면서 docker안에서 테스트 해보는 과정이 필요할듯.  

production환경의 경우 export하는 값들 자체가 db, redis 말고는 다 같은데 따로 또 해줘야 하나 싶다. 
(생각해 보면 production환경 자체가 이제는 redis도 aws elastich cache것을 써서.. 
사실상이것을 eb deploy안하고 런해서 celery-redis 이용한 알람등 작동 테스트 하는게 
가능한가?  ->아니다. 해보진 안았지만 될듯함. )    

우리 경우 위 처럼    
**dev환경에서 docker build로 test진행 해주고 배포만 production환경 + eb deploy**로 해주면 될듯. 


**[질문]**   
우리 프로젝트 경우   
dev는 Dockerfil.dev를 build하고 docker run하는 반면    
production은 Dockerfile작성하면 eb deploy통해서 docker build등이 자동으로 동작하는데..  
이 두가지 실행 했을때의 전체 구조가 정확히 같다고 볼 수있는지?     

답변: 
아니다. -> 후자의 경우 roadbalancer도 있고,  route 53도 있고 다름. 
그럼 dev에서 docker로 테스트 통과 후에 productoion환경 가지고 eb deploy했을때    
애러 생길 가능성 있는것 아닌가? 음. 그런듯하다. 

결국에는 dev용 eb ec2,  production용 eb ec2 따로 두고    
dev.maro5.com, maro5.com 따로 연결해줘서 써야 할 것 같다. 


**[질문]** 
그러면 최종적으로는 어떻게 가야하나?   
(cnameswap생각 x, 일반적인 dev, production용 ec2따로 있는 경우)   

(travis) dev 환경  + docker로 test -> dev환경에 eb deploy  -> 사이트 동작 확인 
[질문] 이경우 dev도메인에 배포된것이 문제없는것은 어떻게 테스트 할지? 
(전체 통합하는 무언가로) dev 브렌치, master 브렌치 병합. -> production 으로 eb deploy 


**[질문]**     
commit 단위 테스트, 배포, 병합 자동화 는 어떻게 할것일까 추측   
```
( travis) 에서 dev환경 테스트 -> docker로  test ->  통과시 master로 dev브렌치 병합. (아마 도메인 연결된 상황을 테스트 하진 않았을것) -> prodcution환경으로 deploy 
```

**[질문]**   
위의 과정이 travis에서 다 되긴 하나? 
test는 dev에서 하고 그것의 결과로 빌드가 일어나고 그것을 s3에 저장하고 배포하는 과정일탠데 
어쨋든 머지하게 되면 zip이 정확히 production을 위해 s3에 eb deploy시 저장 하는것과 같을지?  
 -> 머지한다면 dev, master브렌치 둘다    
  ([여기](https://jojoldu.tistory.com/265) 초기 test후 s3에 deploy하는 과정 보면 빌드 결과는    
  test이후에 어쨌든 테스트 대상에 대해서 생기고 이걸 deploy해야 올라가는듯. )
 
[질문]       
ec2 하나인 우리경우 어떻게 해야 하나?       
travis + eb만 생각해보면.    




**그래서 이시점에서 해볼 수 있는것 쭉 일단 해보자**      


[애러내용]   
```
django.db.utils.OperationalError: could not connect to server: Connection timed out
    Is the server running on host "eb-docker.c0afkt97bzcd.ap-northeast-2.rds.amazonaws.com" (52.78.187.218) and accepting
    TCP/IP connections on port 5432?  
```

Postgresql을 python에서 작동할 수 있도록 도와주는 psycopg2 이것이 문제인듯?     
->다시깔아도 그대로 오류..... 

[개발새발로그](https://dgkim5360.tistory.com/entry/install-psycopg2-python-postgresql-adapter-for-linux-and-windows ) 여기 보면     
추측 ->  rds 보안그룹 에 내가 접속한 ip안들어가 있으면 db에 접속 안된다.    
한양대 탐탐 ip 추가 하기 전에 그냥 내 pc에서도 dev환경 import후 python manage.py test 안됬다.    
트레비스가 내 코드를 받아서 테스트를 돌리는 곳의 ip를 따로 추가 보안그룹에 추가 해줘야 하는것 아닌가 싶다.        

1. 이것을 추가해 줘야해나 말아야 되나 한번 찾아보고 
2. 위에 코드 참고해서 docker build.dev해보고 docker run들어가서   
    python manage.py test해봐서 이때 db포트에의한 문제가 없는지 보자. 

```
A connection timeout error suggests that the database server is not accessible with your settings over the network in a way that does not return an immediate error. The best approach, in my experience, is to troubleshoot the two sides of the connection separately. This means testing the server-side of the connection from the psql command line first, and then testing the django side once that is resolved.   
```

이거 보면 어쨌든 접속을 못해서 뜨는 에러 

```
장고 프로젝트 역시 다른 웹 프레임워크와 마찬가지로 모듈의 로직을 검증하기 위한 유닛테스트가 존재합니다. 테스트를 위한 추가적인 
모듈을 설치해서 좀더 편리하게 유닛테스트를 진행할 수도 있지만, 일단은 장고에서 기본적으로 지원하는 테스트 기능을 이용해서 테스트 해보았습니다.
그런데, 장고에서 유닛테스트를 진행해보면, 한가지 문제가 발생합니다. 바로 검증 데이터를 저장하기 위한 테스트 DB 를 생성한다는 점인데요.
저도 사실 이 테스트 DB 가 생성되는 이유는 잘 모르겠습니다. 테스트 DB 가 새로운 테스트를 실행될 때마다 매번 지워졌다 새로 생성 되기 때문이죠.
 만약 테스트 데이터를 보존해서 테스트 결과를 누적하기 위함이라면 몰라도 실행할 때마다 사라지는 테스트 DB 를 굳이 만들어 내는 이유가 무엇인지 궁금하네요.   
 ```
-> 이거 보면 디비 는 무조건 생성하는듯? 

```
services: postgresql
install:
- pip install -r requirements.txt
- pip install psycopg2
before_script:
- psql -c "CREATE DATABASE mydb;" -U postgres
```

이것들 추가해줘봤는데 효과없고 에러 그대이다.



아무튼 잠정적으로 
테스트 할때마다 디비 생성해주고 
거기 정보 넣어줘야 하는듯. 

[여기](https://brunch.co.kr/@hjinu/6) 보니 

```
3. 데이터베이스 설정하기travis-ci에서 테스트를 실행할 때 테스트용 데이터베이스를 만들기 때문에 database.yml의 내용이 필요하다.
 database.yml 파일은 형상관리를 통해 관리하지 않기 때문이기도 하고 실제 서버의 설정 내용과 다르기 때문에 travis-ci용 데이터베이스 설정파일이 필요하다.
 config/database.yml.travis 라는 파일에 travis를 위한 데이터베이스를 정보를 명시한다.
```

[공식문서](https://docs.travis-ci.com/user/database-setup/) 디비관련 읽어보니 이것인듯.  


```
If your local test setup uses different credentials or settings to access the local test database, 
we recommend putting these settings in a database.yml.travis in your repository and copying that over as part of your build:

database.yml
test:
  adapter: postgresql
  database: travis_ci_test
YAM
.travis.yml 
before_script:
  - cp config/database.yml.travis config/database.yml
```


시도해 보면 애러뜸. 

[애러내용]
```
0.01s
$ cp database.travis.yml config/database.yml
cp: cannot create regular file ‘config/database.yml’: No such file or directory
The command "cp database.travis.yml config/database.yml" failed and exited with 1 during  
```
config 폴더가 travis를 실행하는 pc 안에 없나보다. 

 [여기](https://github.com/rapid7/metasploit-framework/tree/master/config)보면 아예   config폴더를 생성하고 설정파일 거기 놓어놓고 travis에서 복사 해줬는데 이렇게 한번 해봄.  

->여전히 이애러뜸.   
```
django.db.utils.OperationalError: could not connect to server: Connection timed out
    Is the server running on host "eb-docker.c0afkt97bzcd.ap-northeast-2.rds.amazonaws.com" (52.78.187.218) and accepting
    TCP/IP connections on port 5432?  
```
database.yml이 적용 안된듯. 

-->알고보니 database.yml로 설정 바꾸는거.  .. rails에서만 되는것이었다.    
```
For a Rails application, you can now use the following database.yml configuration to access the database locally .
```   

[이글](https://www.lesinskis.com/travis_ci_django.html)보니 트레비스를 위한 환경변수 아예 하나 만들고 그것 임포트 해서 디비 생성하는듯. 이렇게 해보자.   

dev랑 같은 환경 만들되 디비는 로컬껄 쓰겠다는것.  
config.에 travis환경 추가해주고 wsgi만들고 travis.yml에서 임포트 해봄.  
기존의 저 rails fucker는 다 지워줌.  
```
language: python
python:
- 3.6.5
services: postgresql
before_install:
- openssl aes-256-cbc -K $encrypted_da74d99eb5e9_key -iv $encrypted_da74d99eb5e9_iv
-in secrets.tar.enc -out secrets.tar -d
- tar xvf secrets.tar
- export DJANGO_SETTINGS_MODULE=config.settings.travis
install:
- pip install -r requirements.txt
before_script:
- psql -c 'create database travis_ci_db;' -U postgres
script:
- python app/manage.py test  
```
-> 오 빌드가 됬다.   
전체코드는 [깃](https://github.com/maro99/yapen_new/commit/69f7337f3b1561598fe6e4df197fb2bd04d77009) 에 푸쉬했다.


##### 생각해보니 배포와 커밋은 다르다 ! 
배포는 배포고 커밋은 커밋이다.    
즉 배포는 어느 시점의 이미지로 해도 무방하고   
커밋및 머지 등은 그것은 또그것 따로 일어나는것.   
내 과정을 앞으로 어떻게 할지 생각해보면.     
dev환경 으로 테스트  -> 테스트 통과했을때  (브랜치 상관없이 전체 프로젝트)    
빌드되는  파일로 s3저장하고 그것을 마스터 환경으로 eb  배포.   
또한 동시에 dev 환경에 작성하던 코드를 master브렌치에 머지  
어짜피 dev, master배포되는 시점에서 내용 같아지기 때문에. 머지 해도 의미는 같음 .   
결과적으로 master로 배포한것. 
맞는것 같기다. 



위에 코드 참고해서 docker build.dev해보고 docker run들어가서    
python manage.py test해봐서 이때 db포트에의한 문제가 없는지 보자. 
(나는 celery worker도 돌려야 하고 redis 돌려놓고 해야되 반드시 docker에서 테스트 해야할듯  
--> library movie가서 로긴 잘되나 테스트 해보자. + 나한태 딱 필요한 테스트 해줘보자.)    

[여기](https://akhil.work/docker-reactjs-github-travis-ci-aws-part-4/) 처럼    
```
#Tell Travis that we need super user permissions
sudo: required
services:
#Tell Travis that we need docker
  - docker
 
#Tell Travis that before executing the script, create the docker image from the DevDockerfile.
before_install:
  - docker build -t akhil/docker-react-aws -f Dockerfile.dev .
 
#Tell Travis to execute tests (-- -- Coverage will exit npm run test and print out the code coverage)
script:
  - docker run akhil/docker-react-aws npm run test -- --coverage
 
deploy:
  #specify the provider
  provider: elasticbeanstalk
  #specify the region where the provider is present, You can get this from the AWS ElasticBeanstalk dashboard
  region: "us-east-2"
  #Specify the application name in AWS elastic beanstalk
  app: "docker-react-aws"
  #Specify the environment name in AWS elastic beanstalk
  env: "DockerReactAws-env"
  #Specify the Bucket name which is the name of the S3 (storage) which is created as part of Elastic beanstalk in AWS
  bucket_name: "elasticbeanstalk-us-east-2-310307354087"
  #specify the path of the Bucket , this will be similar to the App name above
  bucket_path: "docker-react-aws"
  #specify when you want to deploy (we want to deploy only when we push code to master branch)
  on:
    branch: master
  #Specify the Environment variable name from which Travis can get the ACCESS_KEY to AWS
  access_key_id: $AWS_ACCESS_KEY
  #Specify the Environment variable name from which Travis can get the SECRET_KEY to AWS
  secret_access_key:
    secure: "$AWS_SECRET_KEY"
```


일단 dev랑 최대한 비슷하게 travis 의 secret, config, Dockerfile구성해줬다.  
(디비 환경이 달라서 만들어 줄수밖에 없는듯..) 

build.py도 travis에 맞게 작성해주고 travis.yml안에서 스크립트로 빌드및 도커런 해보자.    
(이거 library movie랑 도커 빌드할때 이름 같으니...추후에 조심조심. ) 
배포시에 쓰는 환경변수는 travis로. 브렌치 새로 나누는게 아님.    
그냥 환경 변수만 만들어 놓고 도커 빌드및 테스트 할때만 사용하겠다. 

travis환경변수 임포트해서 런서버 해봄 -> 설정에 postgresql쓰는데 나는 로컬에 없으니..  
당연히 애러뜸 (travis.yml을 이용한 테스트에서는 코드로 생성했으니 애러 안뜬것)  
 
[이거](https://mrsence.tistory.com/tag/django%EC%99%80%20postgreSQL%20%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0) 따라서 기본적으로 생성 해주고.  깃이그노에 추가  
만약에 ~ 로컬에서 지금처럼 임시로 docker run travis할경우, 혹은  runserver를   
travis임포트후 할경우 에는 필요할것.  
하지만 일반적인 트레비스 목적대로 쓴다면 불필요할것. 일단 해보자.  

```
5. postgreSQL 설치 및 실행
- 설치
- sudo apt-get libpq-dev postgresql postgresql-contrib
- DB 접속 및 데이터베이스 생성
- sudo su - postgres  # postgres 유저 로그인
- psql                # postgres cli 접속
- CREATE DATABASE myproject; # DB 생성
- USER 생성 및 권한 부여
- CREATE USER myprojectuser WITH PASSWORD 'password';
- ALTER ROLE myprojectuser SET client_encoding TO 'utf8';
- ALTER ROLE myprojectuser SET default_transaction_isolation TO 'read committed';
- ALTER ROLE myprojectuser SET timezone TO 'Asia/Seoul';
- GRANT ALL PRIVILEGES ON DATABASE myproject TO myprojectuser;
        

6. django 와 postgre 연결하기
- cd /download-path/Django-1.10/django/bin/myproject/
- vi setting.py
# 추가
DATABASES = {
'default': {
'ENGINE': 'django.db.backends.postgresql_psycopg2',
'NAME': 'myproject',
'USER': 'myprojectuser',
'PASSWORD': 'password',
'HOST': 'localhost',
'PORT': '5432',
}
}
          
- python manage.py makemigrations
- python manage.py migrate
```   

생각해 보니 로컬에서 postgresql생성해서 쓰는건 그거대로고      
->로컬에서 환경 임포트 후 런서버시 사용됨 도커 안에서 postgresql따로 생성해야 되는게 맞는듯. 


딜레마가. 
docker안에서 postgresql따로 생성 하도록 하는 travis 환경 가지고    
docker build하고 테스트 까지 하면 이것이 deploy되나?  
-> 그렇지는 않다. 결국에는 master환경을 기초 코드 바탕으로 deploy할꺼라서 

아니면 travis 환경에서만  docker compose써서 따로  하나의 컨테이너에 postgresql생성하고   
다른 컨테이너에 기존의 장고 코드들 놓고 연동하는거 어떤가? 
멀티 컨테이너 공부하면서 해볼만 하지 않나? 
[한국블로그](https://codethief.io/ko/docker-django-postgresql/ ),  
[외국블로그](https://medium.com/@michealjroberts/using-docker-compose-to-setup-a-simple-django-postgresql-application-46cb22521286) ,[형태형꺼](https://github.com/HyungtaeMoon/REST-API-TDD) 보고 해보면 좋긴할듯. 


**일단 docker compose 해보자 !** 

travis.yml에서  db의  페스워드 및 유저 지정하는 코드    
```
before_script:
- psql -c "CREATE DATABASE testing_db;" -U postgres
- psql -c "CREATE USER foo WITH PASSWORD 'bar';" -U postgres
```

docker run 할때 포트 번호 햇갈림   
```
docker run --rm -it -p 9994:8000 eb-docker:local python /srv/project/app/manage.py runserver 0:8000        ->    이거할때 우리가 수동으로 런서버 해주면 이렇게 했고 
docker run --rm -it -p 9994:80 eb-docker:dev   nginx 의  80 열린것을 활용하면 이렇게 했다.

-p 8000:8000 : 호스트의 8000번 포트(앞)와 컨테이너의 8000번 포트(뒤)를 연결해줍니다.   
```

[docker-compose활용법](http://raccoonyy.github.io/docker-usages-for-dev-environment-setup/)    

docker-compose up 하면 빌드및 런까지 해준다.함.      
```
나름의 팁
1. docker-compose.yml을 수정했다면?
docker-compose.yml 파일을 수정하고 이를 서비스에 적용하려면 서비스를 멈추고(stop), 서비스를 지우고(rm), 서비스를 시작해야(up) 합니다.
하지만 up 명령만 실행해도, (현재 실행 중인 서비스 설정과 달라진 부분이 있다면) 알아서 컨테이너를 재생성하고 서비스를 재시작해줍니다.
$ docker-compose up -d [<서비스 이름>]
혹시 컨테이너를 재생성하지 않는 것 같다면, --force-recreate 옵션을 붙이면 됩니다.

2. Dockerfile-dev 파일을 수정했다면?
Dockerfile-dev 파일을 수정했을 땐 build 명령을 사용하여 도커 이미지를 새로 만들어야 합니다. 이후 서비스 중지와 삭제, 재시작을 해야 하죠.
하지만 up 명령에 다음과 같이 --build 옵션을 넣으면 알아서 이미지를 새로 만들고 서비스를 재시작합니다.
$ docker-compose up -d --build [<서비스 이름>]   
```
디비부분 주석처리 해보니 메인 페이지 까지 접속 되긴함   
```
version: '3.3'


services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.travis
    expose:
      - "80"
    ports:
      - "8000:80"
#    links:
#      - postgres
#  postgres:
#    build:
#      context: ./postgres
#      dockerfile: Dockerfile
#    ports:
#      - "5432:5432"
```




주석풀고 디비내용 포함하니 애러뜸 

 [애러내용]   
 ```
ERROR: for postgres  Cannot start service postgres: driver failed programming external connectivity on endpoint yapen_new_postgres_1 (6
Error starting userland proxy: listen tcp 0.0.0.0:5432: bind: address already in use
```

->답변 

lsof -i :5432  
![](https://i.stack.imgur.com/EzbzO.png)  
```
It seems that docker (1.12.0-rc3-beta18) is using an instance of postgres for something (I killed the service and it forced docker to restart). 
To fix it, I changed my docker-compose ports section from 5432:5432 to just 5432 and let docker choose the port automatically.  
```



한번 하란대로 포트 5432만남기고 해보겠슴   
(이렇게하면 도커가 앞의 host에 대한 포트는 알아서 찾아간다함)
뭔가 되긴했고 로그는 다음과 같았다.    
```
Recreating yapen_new_postgres_1 ... done
Recreating yapen_new_app_1      ... done
Attaching to yapen_new_postgres_1, yapen_new_app_1
app_1       | /usr/lib/python2.7/dist-packages/supervisor/options.py:298: UserWarning: Supervisord is running as root and it is searching for its configuration file in default locations (including its current working directory); you probably want to specify a "-c" argument specifying an absolute path to a configuration file for improved security.
app_1       |   'Supervisord is running as root and it is searching '
postgres_1  | The files belonging to this database system will be owned by user "postgres".
postgres_1  | This user must also own the server process.
postgres_1  |
app_1       | 2019-06-01 06:29:20,859 CRIT Supervisor running as root (no user in config file)
app_1       | 2019-06-01 06:29:20,859 INFO Included extra file "/etc/supervisor/conf.d/supervisor.conf" during parsing
postgres_1  | The database cluster will be initialized with locale "en_US.utf8".
postgres_1  | The default database encoding has accordingly been set to "UTF8".
postgres_1  | The default text search configuration will be set to "english".
postgres_1  |
postgres_1  | Data page checksums are disabled.
postgres_1  |
postgres_1  | fixing permissions on existing directory /var/lib/postgresql/data ... ok
postgres_1  | creating subdirectories ... ok
postgres_1  | selecting default max_connections ... 100
postgres_1  | selecting default shared_buffers ... 128MB
postgres_1  | selecting dynamic shared memory implementation ... posix
postgres_1  | creating configuration files ... ok
postgres_1  | running bootstrap script ... ok
app_1       | 2019-06-01 06:29:20,867 INFO RPC interface 'supervisor' initialized
app_1       | 2019-06-01 06:29:20,868 CRIT Server 'unix_http_server' running without any HTTP authentication checking
app_1       | 2019-06-01 06:29:20,868 INFO supervisord started with pid 7
postgres_1  | performing post-bootstrap initialization ... ok
app_1       | 2019-06-01 06:29:21,871 INFO spawned: 'nginx' with pid 10
app_1       | 2019-06-01 06:29:21,874 INFO spawned: 'uwsgi' with pid 11
app_1       | 2019-06-01 06:29:23,573 INFO success: nginx entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
app_1       | 2019-06-01 06:29:23,574 INFO success: uwsgi entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
postgres_1  | syncing data to disk ...
postgres_1  | WARNING: enabling "trust" authentication for local connections
postgres_1  | You can change this by editing pg_hba.conf or using the option -A, or
postgres_1  | --auth-local and --auth-host, the next time you run initdb.
postgres_1  | ok
postgres_1  |
postgres_1  | Success. You can now start the database server using:
postgres_1  |
postgres_1  |     pg_ctl -D /var/lib/postgresql/data -l logfile start
postgres_1  |
postgres_1  | ****************************************************
postgres_1  | WARNING: No password has been set for the database.
postgres_1  |          This will allow anyone with access to the
postgres_1  |          Postgres port to access your database. In
postgres_1  |          Docker's default configuration, this is
postgres_1  |          effectively any other container on the same
postgres_1  |          system.
postgres_1  |
postgres_1  |          Use "-e POSTGRES_PASSWORD=password" to set
postgres_1  |          it in "docker run".
postgres_1  | ****************************************************
postgres_1  | waiting for server to start....2019-06-01 06:29:31.853 UTC [45] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
postgres_1  | 2019-06-01 06:29:32.506 UTC [46] LOG:  database system was shut down at 2019-06-01 06:29:21 UTC
postgres_1  | .2019-06-01 06:29:32.913 UTC [45] LOG:  database system is ready to accept connections
postgres_1  |  done
postgres_1  | server started
postgres_1  |
postgres_1  | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
postgres_1  |
postgres_1  | waiting for server to shut down....2019-06-01 06:29:33.122 UTC [45] LOG:  received fast shutdown request
postgres_1  | 2019-06-01 06:29:33.382 UTC [45] LOG:  aborting any active transactions
postgres_1  | 2019-06-01 06:29:33.384 UTC [45] LOG:  background worker "logical replication launcher" (PID 52) exited with exit code 1
postgres_1  | 2019-06-01 06:29:33.384 UTC [47] LOG:  shutting down
postgres_1  | .2019-06-01 06:29:34.699 UTC [45] LOG:  database system is shut down
postgres_1  |  done
postgres_1  | server stopped
postgres_1  |
postgres_1  | PostgreSQL init process complete; ready for start up.
postgres_1  |
postgres_1  | 2019-06-01 06:29:34.814 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
postgres_1  | 2019-06-01 06:29:34.814 UTC [1] LOG:  listening on IPv6 address "::", port 5432
postgres_1  | 2019-06-01 06:29:34.940 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
postgres_1  | 2019-06-01 06:29:35.133 UTC [54] LOG:  database system was shut down at 2019-06-01 06:29:34 UTC
postgres_1  | 2019-06-01 06:29:35.302 UTC [1] LOG:  database system is ready to accept connections
```


보면 디비는 일단 postgres컨테이너 생성하면서 같이 생성됬고         
앞서 만든 디비를 마이그레이션 하기 위한 entrypoint.sh 는 실행 됬는지 안됬는지 모르겠슴. 

**해봐야할것**  

다시 docker compose up하고 
##### 0.전체 실행중인 프로세스 확인 -> 엡, 
docker ps해보니    
```
49b9ab570d75        yapen_new_app        "/bin/sh -c 'supervi…"   12 minutes ago      Up 12 minutes       0.0.0.0:8000->80/tcp      yapen_new_app_1
1ea8dc6466e4        yapen_new_postgres   "docker-entrypoint.s…"   12 minutes ago      Up 12 minutes       0.0.0.0:32768->5432/tcp   yapen_new_postgres_1   
```
->   일단 컨테이너 두개 도는것은 확인됨 

포트 대한 내용 햇갈려서 찾아본것     
```
Container Port 외부로 노출(expose) 하기

container 를 생성하면 기본적으로 외부와 통신이 불가능한 상태이다. 따라서 외부와 통신을 위해서는 container를 외부로 노출할 Port를 지정해야한다. 노출할 port를 지정하는 방법은 container 를 생성할때 -p option을 이용하면 된다.
root@~~# docker run -d -p 8080:80 --name web_svr01 httpd

위 명령대로 실행하면, 외부에서 Docker host 의 8080 포트로 요청이 들어오면 web_svr01 컨테이너의 80 포트로 해당 요청을 forwarding 하겠다는 의미이다. 아래와 같이 container 상태를 살펴 보면 8080 -> 80 포트로 forwarding 되어 있는 것을 볼 수 있다.

출처: https://bluese05.tistory.com/53 [ㅍㅍㅋㄷ]
```

#### 1.디비 생성된거 맞나?   -> docker exec으로 postgres 컨테이너 들어가서 디비 확인해보기   

[여기](https://judo0179.tistory.com/48)  따라 해봤는데 디비 생성 안되서 생성해줌.     
설정 스크립트 추가는 안해봤음.   
```
아래와 같이 최신 postgres Docker 이미지를 다운로드 받습니다.
$ docker pull postgres
admin 비밀번호를 셋팅하는 방법은 다음과 같습니다.
$ docker run -d -p 5432:5432 --name pgsql -e POSTGRES_PASSWORD=mysecretpassword postgres
Docker 볼륨을 생성하여 데이터를 계속해서 유지해야 한다면 다음 옵션을 사용합니다.
$ docker volume create pgdata
$ docker run -d -p 5432:5432 --name pgsql -it --rm -v pgdata:/var/lib/postgresql/data postgres
컨테이너에 접속하여 postgres 설정을 진행합니다.
$ docker exec -it pgsql bash

root@cb9222b1f718:/# psql -U postgres
psql (10.3 (Debian 10.3-1.pgdg90+1))
Type "help" for help.
postgres=# CREATE DATABASE mytestdb;
CREATE DATABASE
postgres=#\q
기본 이미지에서 추가 초기화 작업을 진행할 경우 다음과 같이 설정을 진행합니다.
다음 예제는 사용자와 데이터베이스를 추가하는 작업입니다.
root@12345# vi /docker-entrypoint-initdb.d/init-user-db.sh

#!/bin/bash
set -e

psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" <<-EOSQL
  CREATE USER docker;
  CREATE DATABASE docker;
  GRANT ALL PRIVILEGES ON DATABASE docker TO docker;
EOSQL  

다음과 같이 설정을 진행했다면 외부에서 데이터베이스를 사용할 수 있습니다.
```



#### 2.마이그레이션 된건가? 
 디비가 없는데 뭔 마이그가 됬겠냐...
한번 장고 docker가서해보겠다.  ->   
```
  File "/usr/local/lib/python3.6/site-packages/django/db/backends/base/base.py", line 194, in connect
    self.connection = self.get_new_connection(conn_params)
  File "/usr/local/lib/python3.6/site-packages/django/db/backends/postgresql/base.py", line 178, in get_new_connection
    connection = Database.connect(**conn_params)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 130, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
django.db.utils.OperationalError: could not connect to server: Connection refused
    Is the server running on host "127.0.0.1" and accepting
    TCP/IP connections on port 5432?  
```  
이런 애러 뜨면서 안됨. 

1번에서 생성한 디비에 스크립트 넣던지 해서 사용자 추가해야할듯.

#### 3.마이그레이션 안됬다면 postgres컨테이너안의 postgres 디비의 환경(유저명페스워드등)과 장고에 넣어논것과 어떻게 연동할지?     

(시크릿이 같이 가서 상관없나? 근데 travis갈때는 또 어떻게 하지    
...->secret.enc로 다 카바 될려나 모르겠다.)

5.이거 도커업 끄면모든 도커 꺼지는 건지? 아니면 어떻게 수동으로 꺼주나?     
-> 도커업 끄면 docker ps에 있던 컨테이너 모두 종료됨. 



근데 저사람 깃보면 postgres경우 아예 디비 생성안해주고 
from postgres이렇게 되있는데 
형태형처럼 디비 설정 초반에 해줘야하는것 아님?   

형태형 코드  (결국엔 이렇게 해주는게 좋아보임 )

```
version: "3"


services:
  app:
    build:
      context: .
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
    command:  >
      sh -c "python manage.py wait_for_db &&                    # 여기보면 이렇게 디비 기다리고 마이그 해주는 스크립트이런식으로 했는데 이게더 좋아보이는데?  
             python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"


    environment:
      - DB_HOST=db
      - DB_NAME=app
      - DB_USER=postgres
      - DB_PASS=supersecretpassword


    depends_on:
      - db


  db:
    image: postgres:10-alpine
    environment:
      - POSTGRES_DB=app
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=supersecretpassword
```



[질문]  
기존의  eb deploy에서 런서버 어떻게 이뤄지고 있는지 ? uwsgi를 실행하면 자동으로 런서버인지? 그게 같은 의미인지? 
의미파악이 좀 안됨. 


[질문]    
elastic beanstalk docker compose




#### 이하는 조사하면서 살펴봤던 링크들 + 대력적인것들 일단 적어놓음.  

### 1. yapen_new에서 한번 travis+ eb 연결 해보겠다. 
[블로그 (JAVA)](https://jojoldu.tistory.com/317  )
[블로그2](https://rainsound-k.github.io/deploy/2018/05/14/django-travis-ci.html) (Django 이거보면 secret을 zip으로 암호화 해서 올리네... )  
[공식문서](https://docs.travis-ci.com/user/deployment/elasticbeanstalk/#running-commands-before-and-after-deploy)   

궁금한 것들 
1. 브렌치 어떤식으로 되나?  
    (내생각엔 각 브렌치에 환경 연결할수 있고,  현제mater 브렌치에 사용중인 환경 돌고있으니.  
    이것 그대로 입력하면 여기 푸쉬할때마다 자동으로 테스트 할것.)  
    (기존에 eb create할때  s3 배포할때마다 zip저장되는 용도로 생겼고, 마스터 브랜치가  
    default로 해당 환경의 브렌치 되서 마스터에 커밋한 내용이 배포되도록 되있다.   
 
2. 그럼 이거 추후에 어떻게 바꿔야 할까?  
    1)마스터에 그대로 놓고 최종적으로 여기서 검사되도록. 
    2)따로 브렌치 만들거나 dev환경 만들고 연결해서 여기 푸쉬하면 자동으로 검사하도록   
    -> 이경우 환경 하나 더 즉 ec2하나더 만들어야되서 비용 부담된다.. (x)   





















### 2.travis ci auto merge 이거 검색해서 성공시 머지하기 해보자. 
[여기](http://def%20build_dev%28%29:%20%20%20%20%20try:%20%20%20%20%20%20%20%20%20/#%20pipenv%20lock%EC%9C%BC%EB%A1%9C%20requirements.txt%EC%83%9D%EC%84%B1%20%20%20%20%20%20%20%20%20subprocess.call('pipenv%20lock%20--requirements%20--dev%20%3E%20requirements.txt',%20shell=True)%20%20%20%20%20%20%20%20%20#%20docker%20build%20%20%20%20%20%20%20%20%20subprocess.call('docker%20build%20-t%20eb-docker:dev%20-f%20Dockerfile.dev%20.',%20shell=True)%20%20%20%20%20finally:%20%20%20%20%20%20%20%20%20#%20%EB%81%9D%EB%82%9C%20%ED%9B%84%20requirements.txt%ED%8C%8C%EC%9D%BC%20%EC%82%AD%EC%A0%9C%20%20%20%20%20%20%20%20%20os.remove('requirements.txt')) 보면      travis merge스크립트를 작성해 놓고 dev브랜치에서 테스트가  
진행중일때만 master 로 머지하도록 되있다.   

나도 그렇게 하자.
배포는 배포고 머지는 머지니까. 
배포시에 쓰는 환경변수는 travis로. 브렌치 새로 나누는게 아님. 
만약 dev에서 테스트 통과시  ->master로 머지  
만약 master에서 테스트 통과시 - > 머지 x 어짜피 마스터니까. 





### travis + eb에서  before deploy에서  git clone 프론트 엔드 해오는것이 가능한지? 
(또한 이것이 커밋되면 안되도록 하고 싶다.)    
( 이미 s3에 올라간게 집파일 인데 .. 이것은 deploy전이아니라 s3에 올라가기    
전이 eb deploy할때 add되게 해야하는데...)     
-> 안되면 hook에서 하면 되지 않나 싶네. runserver는 그이후에되도록 해보자.   
(모든 서버 동작 전에 하는거 있을텐데?)  
 
### eb cli 로 환경 생성 및 삭제   
 
### eb cli로 green 환경 생성 -> cname swap 으로 green환경으로 트레픽 이동 ->  (blue환경 새로운것 배포, 및 테스트)  -> 성공시 cname swap
[ebcli](https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/eb-cli3-configuration.html )
[ebswap](https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/eb3-swap.html)   
[웹에서 버튼으로 cnameswap](https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html)   
```
1. URL swap를 이용한 배포
새로운 어플리케이션 버전을 이용해서 environment를 실행한 다음.
Beanstalk의 application 메뉴에서 URL swap 기능을 사용해서 2개의 environment간의 url을 변경할 수 있음.
이렇게 되면 기존에 접속해 있던 사용자는 이전 environment를 이용해서 서비스를 이용하게 되고
새로 접속하는 사용자는 새로운 environment를 이용한 서비스를 이용하게 되면서 시스템 중단 없이 새로운 버전의 어플리케이션을 배포할 수 있음.
출처: https://arisu1000.tistory.com/27734 [아리수]   
````

### 람다에서 cron써서 travis + eb 주기적으로 최신 코드 test및 deploy하게 해보자. (or + cloud watch) 
[람다 공식문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)   

### travis cron + eb 로 주기적으로  최신코드 test및 deploy 하게 해보자. 
 
### AWS로 배포하기 1,2,3 codebuild, code deploy, code pipeline설명보고 따라하고, 정보 수집.  
[글1](https://jojoldu.tistory.com/281?category=777282)  

### AWS 블루그린 배포 (code pipeline, lambda, codebuild , eb, s3 ) 참고서보고 그대로 해보기.
[참고서](https://aws.amazon.com/ko/quickstart/architecture/blue-green-deployment/)  

[code pipeline에서 람다 호출]( https://docs.aws.amazon.com/ko_kr/codepipeline/latest/userguide/actions-invoke-lambda-function.html)   

[람다 + eb선택시간 재시작](https://aws.amazon.com/ko/premiumsupport/knowledge-center/schedule-elastic-beanstalk-stop-restart/  ) 
 
### code deploy  & ec2 & docker   
[글1](https://velog.io/@jeff0720/Travis-CI-AWS-CodeDeploy-Docker-%EB%A1%9C-%EB%B0%B0%ED%8F%AC-%EC%9E%90%EB%8F%99%ED%99%94-%EB%B0%8F-%EB%AC%B4%EC%A4%91%EB%8B%A8-%EB%B0%B0%ED%8F%AC-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0-2)   









