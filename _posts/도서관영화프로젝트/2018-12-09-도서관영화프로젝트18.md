---
layout: "post"
title: "도서관영화프로젝트18"    
categories:  
- 도서관영화프로젝트      
tags:  
- 일지      
- celery   
- redis 
comments : true    
date: "2018-12-09 18:50"  
---              

# Celery& Redis를 사용한 TaskQueue 시스템 구현 Redis 서버로 ElasticCache 사용     


---   


## 목차     

0. [Django에서 Redis를 이용해 Caching하기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/03/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B813.html) `12.03 완료`  

1. [celery-reids로 local 환경에서 email_sand task](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/04/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B814.html)   `12.04 완료` 

2. [celery+redis로 local환경에서 celery-beat 이용 특정 task 를 que에 넣고 
  정해진 task 알맞은 시간에 수행](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/05/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B815.html)    `12.05 완료` 

3. [celery+redis로 local 환경에서 celery-beat -> 특정task que에 넣고 정해진task >알맞은
  시간에 수행, celery-worker 그때그때 유저 요청시 email-send해주기](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/05/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B815.html)   `12.05 완료` 

4. 이거보고 [공식문서](http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#generic-initd-celerybeat-example) celery-beat 를 init-script  데몬으로
돌리던거
   예전에  celery-worker init.d에 넣어서 실행시키던거
   [이거](https://www.evernote.com/client/web#?anb=true&b=1917b08f-9255-4138-9cc4-fa196bcd2155&fs=true&n=fb0b1c85-09eb-437b-8f15-15ef1521d68d&s=s372&)   redis>서버 background도는 예제 stackoverflow  찾아서 2번 3번 해보자.
   (가능하면 모두 init.d에 일괄적으로 넣어서 해보고 싶다.)  [링크1](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/06/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B816.html),[링크2](https://maro99.github.io/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2018/12/07/%EB%8F%84%EC%84%9C%EA%B4%80%EC%98%81%ED%99%94%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B817.html), `중단` 

5. docker에 넣고 해보기 
   ( 4번 잘 안되면 여기 넘어와서 dev모드에서 docker안에서  이 셋을 supervisor로
실행시키기) `이페이지 이항목 주로 다뤘다.`

6. celery-redis로 production에서 elasticcahe사용, 1번 -> 3 번 구현하기

7. 내프로젝트에 완전 적용
   소셜로긴, 일반로긴 시 전화번호 받도록 해놓고
   일반로긴시는 (sms인증 or email인증 중 선택할수 있도록.)
   특정 시간에 sms 알람 해보고 --->
   사용자에게 해당 날짜 다가오면 그날 task-que에 알림 쌓아놓고 차례로 보내기.      

---          


## 5. docker에 넣고 해보기 (  dev모드에서 docker안에서  이 셋을 supervisor로 실행시키기)

docker dev로 runserver 어떻게 했는지 기억 안난다. 

review
```
# 빌드 및 런서버  

/build.py -m base
/build.py -m dev
docker run --rm -it -p 9994:80 eb-docker:dev           
localhost:9994접속. 

# docker안에 들어가기  

docker ps
docker exec -it 74ce /bin/bash  

1qes5r
(* eb로 배포시 Dokerfile - > ./deploy.sh -> eb open 
   dev모드 local runserver시에는 ./build.py -m base,dev  ->docker run ) 
```   









공식문서에서 제공하는 [링크](https://github.com/celery/celery/tree/master/extra/supervisord/) (파일만있음)  

[블로그글들](http://blog.weirdx.io/post/27791) 한번 찾아보겠다.  

깃 에서 참조한[것](https://github.com/kahee/Sejong-Search-book/blob/master/.config/dev/supervisord.conf)   



와근데 `init.d`, `celeryd` 할 필요가 없나보다....
그냥 명령어 `worker` `celerybeat`, `celeryd`, `redis-server`여기 넣으면 되나본데,,,.????? 

순서 :

**supervisor.conf에 추가**
```
[program:celery]
; Set full path to celery program if using virtualenv
directory=/srv/project/app

command=celery -A config worker -l info

;user=nobody
numprocs=1
stdout_logfile=/var/log/celery.log
stderr_logfile=/var/log/celery_error.log
autostart=true
autorestart=true
startsecs=10

; Need to wait for currently executing tasks to finish at shutdown.
; Increase this if you have very long running tasks.
stopwaitsecs=600

; When resorting to send SIGKILL to the program to terminate it
; send SIGKILL to its whole process group instead,
; taking care of its children as well.
``` 

**2)셀러리 +redis -> task중 하나 실행시켜서 확인, + postman으로 mail보내기 확인**

config.settings.dev로 celery 설정들 옮겨주고     
```
# CELERY + Redis
CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'

CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TAST_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Asia/Seoul'  
#Celery beat가 스케줄러이기 때문에 시간에 대한 정의를 해야함  
```
도커 안에 들어가서 
`apt-get-install redis-server`후 
`redis-server`했고 
`var/log cat celery_error.log`보니까 연결 된것같음.
`redis-cli -h 127.0.0.1 -p 6379` 들어가 봐도 celery키들 잘 보임.   
```
[2018-12-10 14:19:38,605: INFO/MainProcess] Connected to redis://localhost:6379/0
[2018-12-10 14:19:38,613: INFO/MainProcess] mingle: searching for neighbors
[2018-12-10 14:19:39,629: INFO/MainProcess] mingle: all alone
[2018-12-10 14:19:39,693: WARNING/MainProcess] /usr/local/lib/python3.6/site-packages/celery/fixups/django.py:200: UserWarning: Using settings.DEBUG leads to a memory leak, never use this setting in production environments!
```

설치과정 ->dockerfile,   Dockerfile.base에 추가   

```
# redis-server install
RUN apt -y install redis-server
```

실행과정 -> `supervisor`에 `redis-serve`r실행문 적어보자.      
[참고](https://stackoverflow.com/questions/31660691/how-to-run-a-redis-server-and-another-application-inside-docker) 

**supervisor.conf** 에 추가. 
```
[program:redis]
command= redis-server
stdout_logfile=/var/log/redis-server.log
stderr_logfile=/var/log/redis-server_err.log
autorestart=true
```  

`./build.py -m base`,` dev`하고 `docker run`하니  잘된다. 
redis, celery둘다 도커 시작 동시에 잘 돈다. 




**postman으로 테스트 해보자.**   

와..근게 어드민 가려니까 애러뜬다.      
```
ProgrammingError at /admin/login/
relation "django_site" does not exist
LINE 1: ..."django_site"."domain", "django_site"."name" FROM "django_si...  
```    
이거 뭔 .....그때 alluath하다가 잘못해서 그런건가?,,,,, 
[찾아봄.](https://stackoverflow.com/questions/23925726/django-relation-django-site-does-not-exist/25240502 )  여기서는 site를 마이그래이션 하라는데....

[내 커밋](https://github.com/maro99/library_movie/commit/3e824560926b07b90a025c5a2c16e252fe1ae040) 한번 보고 저게 뭔의민지 한번 생각해보라    





다시 해보니 dockerrun 해서localhost접속 자체가 안됨.  
애러내용.     

nginx쪽   
```
2018/12/11 02:17:19 [error] 12#12: *2 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 172.17.0.1, server: localhost, request: "GET / HTTP/1.1", upstream: "uwsgi://unix://tmp/app.sock", host: "localhost:9994"
root@bd46dfa964b7:/var/log/nginx# %                     
```  
uwsgi쪽 
```
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72904 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x56486480e420 pid: 11 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) ***
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11, cores: 1)
```


모르겠어가지고 옛날 커밋으로 돌아가봄.
앞으로 dev브랜치에서 개발하기로 하자....괴롭다...
하지만 이전 커밋 돌아갓는데도  안된다. 
.........
[글1](https://stackoverflow.com/questions/18740635/nginx-upstream-timed-out-110-connection-timed-out-while-reading-response-hea), [글2](https://distinctplace.com/2017/04/22/nginx-upstream-timed-out/) 보는중.

단순히  upstram인 uwsgi의 반응이 느려서 인가?     
아니면 설마...    
해당 ip를 지금 rds에 안올려 나서 일수도 있겠다.   
------->답십리 주소 추가하니 바로되네요...................ㅠㅠㅠㅠㅠ  

일단 그래도 admin은 안들어가지는것은 같음.
admin들어가지게 하고싶다.  
admin안들어가지는 오류 고쳐보자..
이거 결국에는 migration 안해줘서 인듯.
여러가지 패키지 설치 해줬는데 마이그 안해줘서...  
( 기존에 배포시에 알아서 migration되는것은 eb에서만 되던것.   
eb배포시 ebextionsions에 추가로 뭐 해줘서 되던거다!!!!!착각했네요.)  
  
----------------->마이그래이션 하니까 바로된다....  
   
여기까지 했던것들 다시 1)2)번 복구해보자.   
복구하고 다시 postman    
------------>okay 유저 email send까지 확인 해봤다.    




**3)셀러리 +redis+셀러리비트 -> task주기적으로 되나 확인**
**+ postman으로 보내보기 동시에 되나 확인.** 


첫번째로 도커 안에서   
`celery -A config  beat -l info`     
이 명령어 쳐봤는데 처음에는 다음같은 애러떴지만 이내  잘 됬다.   

에러   
```
[2018-12-11 11:35:29,040: ERROR/MainProcess] Removing corrupted schedule file 'celerybeat-schedule': error('Bad magic number',)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/kombu/utils/objects.py", line 42, in __get__
    return obj.__dict__[self.__name__]
KeyError: 'scheduler'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/celery/beat.py", line 476, in setup_schedule
    self._store = self._open_schedule()
  File "/usr/local/lib/python3.6/site-packages/celery/beat.py", line 466, in _open_schedule
    return self.persistence.open(self.schedule_filename, writeback=True)
  File "/usr/local/lib/python3.6/shelve.py", line 243, in open
    return DbfilenameShelf(filename, flag, protocol, writeback)
  File "/usr/local/lib/python3.6/shelve.py", line 227, in __init__
    Shelf.__init__(self, dbm.open(filename, flag), protocol, writeback)
  File "/usr/local/lib/python3.6/dbm/__init__.py", line 94, in open
    return mod.open(file, flag, mode)
_gdbm.error: Bad magic number
```

잘되는 동작   
```
[2018-12-11 11:35:34,196: INFO/MainProcess] Scheduler: Sending due task add-every-5-seconds (sum_two_numbers)
```

`redis-cli 127`~ 에 `task` 키들도 잘 보임    
(그다음 실행부터는 저런 애러 안뜬다. )   
  
`supervisor`로 실행해보자.    
   
이거 `supervisor.conf`에 추가해줌    
```
[program:celerybeat]
; Set full path to celery program if using virtualenv
;command=celery beat -A config --schedule /var/lib/celery/beat.db --loglevel=INFO
command=celery -A config  beat -l info

; remove the -A myapp argument if you aren't using an app instance

directory=/srv/project/app
user=root
numprocs=1
stdout_logfile=/var/log/celery_beat.log
stderr_logfile=/var/log/celery_beat_error.log
autostart=true
autorestart=true
startsecs=10

; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
stopasgroup=true

; if rabbitmq is supervised, set its priority higher
; so it starts first
priority=999
```  

도커런 하면 `celery`, `celerybeat`, `redis`다 잘 실행되고 
`multiply`, sum 잘되고 email도 잘 보내졌다.  






